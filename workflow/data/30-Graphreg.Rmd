---
title: "30-my_batch_pulsar"
output: github_document
---

## GraphReg function
```{r}

Graphreg <- function(data, fun = huge::huge, fargs=list(),
                    criterion = c("stars"), thresh = 0.05, subsample.ratio = NULL,
                    lb.stars=FALSE, ub.stars=FALSE, rep.num = 20, seed = NULL,
                    wkdir=getwd(), regdir=NA, init="init", conffile='',
                    job.res=list(), cleanup=FALSE, refit = TRUE, 
                    prior_graph = NULL, method = c("spearman"), orbind = c(0, 2, 5, 7, 8, 10, 11, 6, 9, 4, 1),
                    use_pseudo_count = FALSE) {

    if (!requireNamespace('batchtools', quietly=TRUE)) {
        stop("'batchtools' package required to run 'batch.pulsar'")
    }
    gcinfo(FALSE)
    if (!is.na(regdir) && file.exists(regdir)) {
        stop('Registry directory already exists')
    }
    
    n <- nrow(data)
    p <- ncol(data)
    knowncrits <- c("stars", "gcd", "gcd_prior", "ghust", "ghust_prior", "estrada", "sufficiency")
    .lamcheck(fargs$lambda)
    .critcheck0(criterion, knowncrits)
    
    if (any(c("gcd_prior", "ghust_prior") %in% criterion) && is.null(prior_graph)) {
      stop("Please provide prior graph structure!")
    }
    
    subsample.ratio <- .ratcheck(subsample.ratio, n)
    nlams <- length(fargs$lambda)
    conffile <- findConfFile(conffile)
    lambda_full <- fargs$lambda

    if (!is.null(seed)) set.seed(seed)
    ind.sample <- replicate(rep.num, sample(c(1:n), floor(n * subsample.ratio), replace = FALSE), simplify = FALSE)
    
    if (refit) {
        tmp <- 1L:n
        attr(tmp, 'full') <- TRUE
        ind.sample <- c(list(tmp), ind.sample)
    }
    if (!is.null(seed)) set.seed(NULL)

    estFun <- function(ind.sample, fargs, data, fun) {
        tmp <- do.call(fun, c(fargs, list(data[ind.sample,])))
        if (!('path' %in% names(tmp))) {
            stop('Error: expected data structure with \'path\' member')
        }
        if (isTRUE(attr(ind.sample, 'full'))) {
            return(tmp)
        } else {
            return(tmp$path)
        }
    }

    est <- list()
    reduceargs <- list()
    reduceGCDargs <- list()
    reduceGGDargs <- list()
    reduceGCDargs_pseudo <- list()
    lb.gcdpremerge <- list()
    lb.gcdpremerge_pseudo <- list()
  
    # If lb.stars TRUE, only consider first two subsamples (+ refit)
    if (lb.stars) {
        if (!("stars" %in% criterion)) {
            stop('Lower/Upper bound method must be used with StARS')
        }
        minN <- 2 + refit 
        if (!is.na(regdir)) regdir <- paste(regdir, init, sep = "_")
    } else {
        minN <- rep.num + refit 
    }
    
    isamp <- ind.sample[1:minN] 
    out <- batchply(data, estFun, fun, fargs, isamp, wkdir, regdir, conffile, job.res) 
    reg <- out$reg 
    id <- out$id # manage and track the submitted batch jobs
    doneRun <- batchtools::waitForJobs(reg = reg, id) 
    jdone <- batchtools::findDone(reg = reg, id) # Identifies which jobs have completed successfully
    pulsar.jobs <- intersect((1 + refit):minN, jdone$job.id) 

    if (refit) { # option to refit the model using the full dataset (not just subsamples)
        fullmodel <- batchtools::loadResult(id = 1, reg = reg) 
        minN <- minN - 1L 
    } else {
        fullmodel <- NULL 
    }
    
    ## Merge Function Stars
    # Custom function defined to aggregate the results of the subsampled analyses
    # starsaggfun <- function(res, aggr) lapply(1:length(aggr), function(i) aggr[[i]] + res[[i]])
    
    ## Premerge Function Stars
    starsaggfun <- function(res, aggr) {
      if (is.null(aggr)) {
        aggr <- vector("list", length(res))
        for (i in seq_along(aggr)) {
          aggr[[i]] <- list()
        }
      }
      
      for (i in seq_along(res)) {
        aggr[[i]] <- append(aggr[[i]], res[[i]])
      }
  
      return(aggr)
    }
    
    
    if (lb.stars) {
      
        # Store the registry and job IDs
        est$init.reg <- reg 
        est$init.id <- id

        if (!doneRun) {
            stop('Errors in batch jobs for computing initial stability')
        }
        
        # Collect initial StARS results using premerge
        lb.starspremerge <- batchtools::reduceResults(reg = reg, ids = pulsar.jobs, fun = starsaggfun)
        lb.est <- stars.stability(premerge = lb.starspremerge, thresh, minN, p, merge = NULL)
        est$lb.starspremerge <- lb.starspremerge

        # Collect initial StARS results using merge
        #lb.est <- stars.stability(NULL, thresh, minN, p, lb.starsmerge) 
        gc(FALSE)
        
        # Collect initial GhUST results using premerge
        if ('ghust' %in% criterion || 'ghust_prior' %in% criterion) {
          aggfun <- function(res, ...) {
            lapply(res, function(x) ggvec(x, ...))
          }
          
          lb.ggdpremerge <- do.call(batchtools::reduceResultsList,
                                                     c(list(reg = reg, ids = pulsar.jobs, fun = aggfun), reduceGGDargs))
          est$lb.ggdpremerge <- lb.ggdpremerge
        }
        
        # Collect initial GCD results using premerge
        if ('gcd' %in% criterion || 'gcd_prior' %in% criterion) {

            for (meth in method) {
              
              if (use_pseudo_count == TRUE) {
                
                # Gather GCV for pseudo
                aggfun <- function(res, ...) {
                    lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind,
                                                     pseudo_count = TRUE, ...))
                }
                
                lb.gcdpremerge_pseudo[[meth]] <- do.call(batchtools::reduceResultsList,
                                                       c(list(reg = reg, ids = pulsar.jobs, fun = aggfun), reduceGCDargs_pseudo))
                #est[[paste("lb.gcdpremerge_pseudo", meth, sep = "_")]] <- lb.gcdpremerge_pseudo[[meth]]
                
              }
              
              
              # Gather GCV 
              aggfun <- function(res, ...) {
                  lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind, ...))
              }
      
              lb.gcdpremerge[[meth]] <- do.call(batchtools::reduceResultsList,
                                                     c(list(reg = reg, ids = pulsar.jobs, fun = aggfun), reduceGCDargs))
              #est[[paste("lb.gcdpremerge", meth, sep = "_")]] <- lb.gcdpremerge[[meth]]
              
            }
        }
        

        if (cleanup) unlink(reg$file.dir, recursive = TRUE) # deletes temporary files created during batch job execution
        if (lb.est$opt.index == 1) {
            warning("Accurate lower bound could not be determined with the first 2 subsamples")
        }
        
        # Upper bound is determined by maximum entropy of Poisson Binomial
        if (ub.stars) { 
            pmean <- sapply(lb.est$merge, function(x) sum(x) / (p * (p - 1))) 
            ub.summary <- cummax(4 * pmean * (1 - pmean)) 
            tmpub <- .starsind(ub.summary, thresh, 1) 
            ub.index <- if (any(ub.summary == 0)) { 
                max(tmpub, max(which(ub.summary == 0)) + 1)
            } else {
                max(tmpub, 1)
            }
        } else {
            ub.index <- 1
        }
        
        # Adjusts lambda path to be within the bounds
        fargs$lambda <- fargs$lambda[ub.index:lb.est$opt.index] 
        nlams <- length(fargs$lambda)
        
        # Prepare arguments for reducing results in the subsequent batch jobs
        reduceargs <- list(init = lb.starspremerge[ub.index:lb.est$opt.index])
        
        if ('ghust' %in% criterion || 'ghust_prior' %in% criterion) {
          reduceGGDargs <- list(init = lapply(lb.ggdpremerge, function(ggdpm) ggdpm[ub.index:lb.est$opt.index]))
        }
        
        if ('gcd' %in% criterion || 'gcd_prior' %in% criterion) { 
        
            for (meth in method) {
              
              if (use_pseudo_count == TRUE) {
                reduceGCDargs_pseudo[[meth]] <- list(init = lapply(lb.gcdpremerge_pseudo[[meth]], 
                                                                function(gcdpm) gcdpm[ub.index:lb.est$opt.index]))
              }
              
              reduceGCDargs[[meth]] <- list(init = lapply(lb.gcdpremerge[[meth]], 
                                                              function(gcdpm) gcdpm[ub.index:lb.est$opt.index]))
            }
        }

        # First minN subsamples already processed, remaining ones are to be handled now
        regdir <- gsub(paste("_", init, sep = ""), "", regdir)
        isamp <- ind.sample[-(1:minN)] 
        out <- batchply(data, estFun, fun, fargs, isamp, wkdir, regdir, conffile, job.res) 
        reg <- out$reg
        id <- out$id
        doneRun <- batchtools::waitForJobs(reg = reg, id)
        jdone <- batchtools::findDone(reg = reg, id)
        pulsar.jobs <- intersect((1 + refit):rep.num, jdone$job.id)
    }

    rep.num <- length(pulsar.jobs)
    if (lb.stars) rep.num <- rep.num + minN
    if (!doneRun) {
        warning(paste("Only", length(jdone), "jobs completed... proceeding anyway"))
    }
    
    updated_criteria <- list()

    for (i in 1:length(criterion)) {
        crit <- criterion[i]
        
        if (crit == "stars") {
          
            starspremerge <- do.call(batchtools::reduceResults,
                                  c(list(reg = reg, ids = pulsar.jobs, fun = starsaggfun), reduceargs))
            
            #est$stars <- stars.stability(premerge = NULL, thresh, rep.num, p, merge = starsmerge)
            est$stars <- stars.stability(premerge = starspremerge, thresh, rep.num, p, merge = NULL)
            est$premerge <- starspremerge
        }
        
        if (crit == "ghust" || crit == "ghust_prior") {
          
          # Gather GGV
          aggfun <- function(res, ...) {
                  lapply(res, function(x) ggvec(x, ...))
          }
          
          ggdpremerge <- c(reduceGGDargs$init,
                           batchtools::reduceResultsList(reg = reg, ids = pulsar.jobs, fun = aggfun))
          est[["ggdpremerge"]] <- ggdpremerge
          
          if (crit == "ghust") {
            est[["ghust"]] <- ggd.stability(premerge = ggdpremerge, rep.num, nlams)
          }
          
          if (crit == "ghust_prior") {
            est[["ghust_prior"]] <- ggd.stability(premerge = ggdpremerge, rep.num, nlams, 
                                                  prior_graph = prior_graph, use_prior = TRUE)
          }
          
        }
        
        if (crit == "gcd" || crit == "gcd_prior") {
          
            for (meth in method) {
              
              if (use_pseudo_count == TRUE) {
                
                # Update criterion to include new methods
                new_criterion_name <- if (crit == "gcd") {
                    paste("gcd_pseudo", meth, sep = "_")
                } else {
                    paste("gcd_prior_pseudo", meth, sep = "_")
                }
                updated_criteria <- c(updated_criteria, new_criterion_name)
                
                
                # Gather GCV for Pseudo
                aggfun <- function(res, ...) {
                  lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind,
                                                         pseudo_count = TRUE, ...))
                }
                
                gcdpremerge_pseudo <- c(reduceGCDargs_pseudo[[meth]]$init,
                                 batchtools::reduceResultsList(reg = reg, ids = pulsar.jobs, fun = aggfun))
                
                
                if (crit == "gcd") {
                    est[[paste("gcd_pseudo", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge_pseudo, 
                                                        rep.num, p, nlams, prior_graph = prior_graph, 
                                                        use_prior = FALSE, method = meth, orbind = orbind)
                    #est[[paste("gcdpremerge_pseudo", meth, sep = "_")]] <- gcdpremerge_pseudo
                }
            
                if (crit == "gcd_prior") {
                    est[[paste("gcd_prior_pseudo", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge_pseudo, 
                                                        rep.num, p, nlams, prior_graph = prior_graph, 
                                                        use_prior = TRUE, method = meth, orbind = orbind)
                    #est[[paste("gcdpremerge_prior_pseudo", meth, sep = "_")]] <- gcdpremerge_pseudo
                }
              }
                
              # Update criterion to include new methods
              new_criterion_name <- if (crit == "gcd") {
                  paste("gcd", meth, sep = "_")
              } else {
                  paste("gcd_prior", meth, sep = "_")
              }
              updated_criteria <- c(updated_criteria, new_criterion_name)

              
              # Gather GCV
              aggfun <- function(res, ...) {
                      lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind, ...))
              }
              
              gcdpremerge <- c(reduceGCDargs[[meth]]$init,
                               batchtools::reduceResultsList(reg = reg, ids = pulsar.jobs, fun = aggfun))
              
              
              if (crit == "gcd") {
                  est[[paste("gcd", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge, 
                                                      rep.num, p, nlams, prior_graph = prior_graph, 
                                                      use_prior = FALSE, method = meth, orbind = orbind)
                  #est[[paste("gcdpremerge", meth, sep = "_")]] <- gcdpremerge
              }
          
              else if (crit == "gcd_prior") {
                  est[[paste("gcd_prior", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge, 
                                                      rep.num, p, nlams, prior_graph = prior_graph, 
                                                      use_prior = TRUE, method = meth, orbind = orbind)
                  #est[[paste("gcdpremerge_prior", meth, sep = "_")]] <- gcdpremerge
              }
              
            }
        }
        
        else if (crit == "estrada") {
          if (!("stars" %in% criterion))
            warning('Need StaRS for computing Estrada classes... not run')
          else
            est$estrada <- estrada.stability(est$stars$merge, thresh, rep.num, p, nlams)
        }

        else if (crit == "sufficiency") {
          if (!("stars" %in% criterion)) warning('Need StaRS for computing sufficiency... not run')
          else  est$sufficiency <- sufficiency(est$stars$merge, rep.num, p, nlams)
        }
    }
    
    if (lb.stars) {
      ## split indices of init and full stars estimate
      pind <- ub.index:lb.est$opt.index
      pinv <- setdiff(1:length(lb.est$summary), pind)
      ## stitch back together init and full stars summaries
      tmpsumm       <- vector('numeric', length(lb.est$summary))
      tmpsumm[pinv] <- lb.est$summary[pinv]
      tmpsumm[pind] <- est$stars$summary
      est$stars$summary <- tmpsumm
      ## stitch back together init and full stars merges 
      tmpmerg <- vector('list', length(lb.est$summary))
      tmpmerg[pinv]   <- lb.est$merge[pinv]
      tmpmerg[pind]   <- est$stars$merge
      est$stars$merge <- tmpmerg
      ## record stars-related indices
      est$stars$lb.index  <- lb.est$opt.index
      est$stars$ub.index  <- ub.index
      est$stars$opt.index <- est$stars$opt.index + ub.index - 1
      
      ## Additional metrics
      est$additional$ind_bound <- pind
      est$additional$ind_rest <- pinv
      est$additional$lb.lambda <- round(lambda_full[lb.est$opt.index], 3)
      est$additional$ub.lambda <- round(lambda_full[ub.index], 3)
      stars_lambda <- round(lambda_full[est$stars$opt.index], 3)
      est$additional$gap_b <- abs(est$additional$ub.lambda - est$additional$lb.lambda)
      est$additional$gap_beta <- abs(stars_lambda - est$additional$lb.lambda)
    }
    
    ## Full and bounded lambda path
    est$additional$lambda_full <- lambda_full
    est$additional$lambda_bound <- fargs$lambda
    
    ## Update criterion vector 
    criterion <- unique(c(criterion, updated_criteria))
    criterion <- setdiff(criterion, c("gcd", "gcd_prior"))
    est$criterion <- criterion
    for (crit in criterion) {
      est[[crit]]$criterion <- crit
    }
    
    ## Compute and set optimal index and lambda directly (excluding StARS)
    for (crit in criterion) {
      if (startsWith(crit, "gcd") || startsWith(crit, "ghust")) {
        gcdind <- which.min(est[[crit]]$summary)

        if (lb.stars){
          gcdind <- gcdind + est$stars$ub.index - 1
        }
        est[[crit]]$opt.index <- gcdind
      }

      est[[crit]]$opt.lambda <- signif(lambda_full[est[[crit]]$opt.index], 3)
    }

    ## Refit section
    if (refit == TRUE) {

      # Refit each criterion with optimal index
      for (crit in criterion) {
        opt_ind <- est[[crit]]$opt.index
        if (!is.null(opt_ind)) {
          est[[crit]]$refit <- fullmodel$path[[opt_ind]]
        } else {
          est[[crit]]$refit <- NULL
        }
      }

      ## Determine adjacency matrices for full lambda path
      for (crit in criterion) {
          if (startsWith(crit, "gcd") || startsWith(crit, "ghust")) {
              est[[crit]]$all_adj <- list()
              for (i in seq_along(fargs$lambda)) {
                  gcdinds <- which(est[[crit]]$summary == est[[crit]]$summary[[i]])
                  if (lb.stars) {
                    gcdinds <- gcdinds + est$stars$ub.index - 1
                  }
                  valid_gcdind <- NULL
                  for (gcdind in gcdinds) {
                      if (!is.null(gcdind) && gcdind > 0 && gcdind <= length(fullmodel$path)) {
                          valid_gcdind <- gcdind
                          break
                      }
                  }

                  if (!is.null(valid_gcdind)) {
                      estim <- fullmodel$path[[valid_gcdind]]
                      est[[crit]]$all_adj[[i]] <- estim
                  } else {
                      est[[crit]]$all_adj[[i]] <- NULL
                  }
              }
          }
      }

      ## Determine F1 score and hamming distance
      if (!is.null(prior_graph)) {
          est$criterion <- c(criterion, c("oracle_f1", "oracle_hamming"))

          est$additional$hamming_dist <- list()
          est$additional$f1_score <- list()

          for (i in seq_along(fargs$lambda)) {
              gcdind <- NULL
              gcdind <- which(fargs$lambda == fargs$lambda[[i]])
              if (lb.stars) {
                gcdind <- gcdind + est$stars$ub.index - 1
              }
              
              if (!is.null(gcdind) && gcdind > 0 && gcdind <= length(fullmodel$path)) {
                  estim <- fullmodel$path[[gcdind]]
                  est$additional$hamming_dist[[i]] <- my.hamming(estimated = estim, actual = prior_graph)
                  est$additional$f1_score[[i]] <- my.f1_score(predicted = estim, actual = prior_graph)
              } else {
                  est$additional$hamming_dist[[i]] <- NA 
                  est$additional$f1_score[[i]] <- NA
              }
          }

          # Define Oracle_f1 and Oracle_hamming
          gcdind <- which.max(est$additional$f1_score)
          if (lb.stars) {
            gcdind <- gcdind + est$stars$ub.index - 1
          }
          est$oracle_f1$opt.index <- gcdind
          est$oracle_f1$opt.lambda <- signif(lambda_full[est$oracle_f1$opt.index], 3)
          est$oracle_f1$refit <- fullmodel$path[[est$oracle_f1$opt.index]]
          est$oracle_f1$sparsity <- sum(est$oracle_f1$refit) / (p * (p - 1))

          gcdind <- which.min(est$additional$hamming_dist)
          if (lb.stars) {
            gcdind <- gcdind + est$stars$ub.index - 1
          }
          est$oracle_hamming$opt.index <- gcdind
          est$oracle_hamming$opt.lambda <- signif(lambda_full[est$oracle_hamming$opt.index], 3)
          est$oracle_hamming$refit <- fullmodel$path[[est$oracle_hamming$opt.index]]
          est$oracle_hamming$sparsity <- sum(est$oracle_hamming$refit) / (p * (p - 1))
      }

      # Calculate sparsity for criteria
      for (crit in criterion) {
        est[[crit]]$sparsity <- sum(est[[crit]]$refit) / (p * (p - 1))
      }

      # Determine GCMs for optimal estimate
      for(crit in criterion) {
        if (startsWith(crit, "gcd")) {

          count <- FALSE
          if(grepl("pseudo", crit)) {
            count <-  TRUE
          }

          meth <- c("spearman")
          if(grepl("kendall", crit)) {
            meth <- c("kendall")
          }
          else if(grepl("latentcor", crit)) {
             meth <- c("latentcor")
          }

          graph <- est[[crit]][["refit"]]
          est[[crit]]$gcm <- my.gcvec(graph = graph, method = meth, pseudo_count = count,
                                        orbind = orbind, return_gcm = TRUE)
        }
      }
    }
    
    if ("stars" %in% criterion) {
      if (est$stars$opt.index == 1) {
        direction <- if (any(est$stars$summary >= .1)) "larger" else "smaller"
        warning(paste("Optimal lambda may be", direction,
                      "than the supplied values"))
      }
    }
    
    if (cleanup) unlink(reg$file.dir, recursive = TRUE)

    est$id <- id
    est$reg <- reg
    est$call <- match.call()
    est$est <- fullmodel
    est$envir <- parent.frame()


    print("Completed batch.pulsar function.")
    return(structure(est, class = c("batch.pulsar", "pulsar")))
}





#########################################################################################################
####################################### GraphReg Functions ##############################################
#########################################################################################################

## Version 1
# Keeping NaNs, lb and ub needs to be turned on
# ggd.stability <- function(premerge, rep.num, nlams, prior_graph = NULL, use_prior = FALSE, ...) {
#
#   est <- list()
#
#   if (use_prior) {
#     ggv_true = ggvec(prior_graph, ...) # gcv for true_graph
#
#     est$merge <- vector("list", nlams)
#     for (i in 1:nlams) {
#         lambda_distances <- numeric(rep.num)
#         for (j in 1:rep.num) {
#             ggv_sub <- premerge[[j]][[i]] # gcv of subsample j and lambda i
#             lambda_distances[j] <- dist(rbind(ggv_sub, ggv_true))[[1]] # calculate ggd
#         }
#         est$merge[[i]] <- lambda_distances
#     }
#   }
#
#   else {
#     est$merge <- lapply(1:nlams, function(i) dist(t(sapply(1:rep.num, function(j) premerge[[j]][[i]]))))
#   }
#
#   est$summary <- vector('numeric', nlams)
#   for (i in 1:nlams) {
#       est$summary[i] <- mean(est$merge[[i]]) # Fill summary: ith lambda = mean over all j subsamples
#   }
#
#   return(est)
# }

## Version 2
ggd.stability <- function(premerge, rep.num, nlams, prior_graph = NULL, use_prior = FALSE, ...) {
  est <- list()

  # Calculate euclidean distance between the 12 dim of each subsample for a specific lambda to the 12 dim of the true graph
  if (use_prior && !is.null(prior_graph)) {
    ggv_true <- ggvec(prior_graph, ...) # ggv for true_graph
    est$merge <- vector("list", nlams)
    for (i in 1:nlams) {
      lambda_distances <- numeric(rep.num)
      for (j in 1:rep.num) {
        ggv_sub <- premerge[[j]][[i]] # ggv of subsample j and lambda i
        if (all(is.finite(c(ggv_sub, ggv_true)))) {
          lambda_distances[j] <- dist(rbind(ggv_sub, ggv_true))[[1]] # calculate ggd
        } else {
          lambda_distances[j] <- NA  # Assign NA if any NaN present
        }
      }
      est$merge[[i]] <- lambda_distances
    }
  } else {
    ## Internal consistency among subsamples
    # Calculate the euclidean distance between the 12 dim of the subsamples for a specific lambda with each other
    est$merge <- lapply(1:nlams, function(i) {
      ggv_matrix <- sapply(1:rep.num, function(j) premerge[[j]][[i]])
      return(dist(t(ggv_matrix)))
    })
  }

  est$summary <- sapply(est$merge, function(distances) if (is.numeric(distances)) mean(distances, na.rm = TRUE) else NA)

  return(est)
}

# ## Version 3
# # Removing all NaNs, lb and ub can be turned off
# ggd.stability <- function(premerge, rep.num, nlams, prior_graph = NULL, use_prior = FALSE, ...) {
#   est <- list()
# 
#   # Calculate euclidean distance between the 12 dim of each subsample for a specific lambda to the 12 dim of the true graph
#   if (use_prior && !is.null(prior_graph)) {
#     ggv_true <- ggvec(prior_graph, ...) # ggv for true_graph
#     est$merge <- vector("list", nlams)
# 
#     for (i in 1:nlams) {
#       lambda_distances <- numeric(rep.num)
#       valid_subs = TRUE
# 
#       for (j in 1:rep.num) {
#         ggv_sub <- premerge[[j]][[i]]
#         if (!all(is.finite(ggv_sub))) {
#           valid_subs = FALSE
#           break
#         }
#       }
# 
#       if (valid_subs && all(is.finite(ggv_true))) {
#         for (j in 1:rep.num) {
#           ggv_sub <- premerge[[j]][[i]]
#           lambda_distances[j] <- dist(rbind(ggv_sub, ggv_true))[[1]] # calculate ggd
#         }
#         est$merge[[i]] <- lambda_distances
#       } else {
#         est$merge[[i]] <- rep(NA, rep.num) # Assign NA if any NaN present in subsamples or true graph
#       }
#     }
#   } else {
#     ## Internal consistency among subsamples
#     # Calculate the euclidean distance between the 12 dim of the subsamples for a specific lambda with each other
#     est$merge <- lapply(1:nlams, function(i) {
#       ggv_matrix <- sapply(1:rep.num, function(j) premerge[[j]][[i]])
#       if (any(!is.finite(ggv_matrix))) {
#         return(rep(NA, rep.num))  # Assign NA to all distances if any NaN present in a lambda set
#       } else {
#         return(dist(t(ggv_matrix)))
#       }
#     })
#   }
# 
#   est$summary <- sapply(est$merge, function(distances) if (is.numeric(distances)) mean(distances, na.rm = TRUE) else NA)
# 
#   return(est)
# }


ggvec <- function(adj_matrix) { #graphlet ghust vector
  # Convert the adjacency matrix to an igraph graph object
  graph <- igraph::graph_from_adjacency_matrix(adj_matrix, mode = "undirected", diag = FALSE)

  # Transform adjacency matrix to edge list if necessary for graphlet counting
  nx2 <- .adj2elist(adj_matrix)
  orbind <- c(0, 2, 1, 3) + 1 
  n <- length(orbind)
  p <- ncol(adj_matrix)
  
  if (ncol(nx2) < 1 || nrow(nx2) < 1) {
      return(rep(NA, 12))  # Return NA vector of length 12 if the graph is empty
  }
  
  # Perform graphlet decomposition to get graphlet degree matrix (gdm)
  gdm <- orca::count4(nx2)
  buffer <- matrix(0, nrow=p-nrow(gdm), ncol=ncol(gdm))
  gdm <- rbind(gdm, buffer)
  #gdm <- rbind(gdm[,orbind],1) 
  gdm <- gdm[,orbind] 
  
  # Binary indicator matrix for node-orbit participation
  Pt <- gdm > 0
  Pt <- 1 * Pt
  
  # # Small number to prevent division by zero
  # epsilon <- 1e-6
  # 
  # # Calculate dimensions based on gdm and Pt
  # rho_1 <- 1 - (2 * sum(Pt[, "O0"]) / (sum(gdm[, "O0"]) + epsilon))
  # #rho_1 <- ifelse(rho_1 >= 0, r1, NA)
  # rho_2 <- 1 - (sum(Pt[, "O2"] * (1 - Pt[, "O3"])) / (sum(Pt[, "O1"] * (1 - Pt[, "O3"])) + epsilon))
  # 
  # rho_3 = (sum(gdm[, "O1"] * Pt[, "O1"] * (1 - Pt[, "O2"]) * (1 - Pt[, "O3"])) /
  #          (sum(Pt[, "O1"] * (1 - Pt[, "O2"]) * (1 - Pt[, "O3"])) + epsilon)) / (max(gdm[, "O0"]) + epsilon)
  # rho_4 = sum(gdm[, "O2"]) / ((sum(Pt[, "O2"]) + epsilon) * (max(gdm[, "O2"]) + epsilon))
  # rho_5 = (0.5 * cov(rank(gdm[, "O1"]), rank(gdm[, "O2"])) /
  #         ((sd(rank(gdm[, "O1"])) + epsilon) * (sd(rank(gdm[, "O2"])) + epsilon))) + 0.5
  # U2 <- ifelse(gdm[, "O2"] == 1, 1, 0)
  # U3 <- ifelse(gdm[, "O3"] == 0, 1, 0)
  # rho_6 = sum(U2 * U3) / (sum(Pt[, "O2"]) + epsilon)
  # n_strings = count_distinct_strings(graph, which(U2 & U3))
  # rho_7 = 1 - (n_strings / (sum(U2 * U3) + epsilon))
  # rho_8 = sum(gdm[, "O3"]) / ((3 * sum(gdm[, "O2"]) + sum(gdm[, "O3"])) + epsilon)
  # rho_9 = 1 - (sum(Pt[, "O3"]) / (sum(gdm[, "O3"]) + epsilon))
  # rho_10 = sum(Pt[, "O3"]) / (sum(Pt[, "O0"]) + epsilon)
  # rho_11 = { numerator_rho_11 = sum(Pt[, "O3"] * U2); numerator_rho_11 / (sum(Pt[, "O3"]) + epsilon) }
  # rho_12 = (sum(gdm[, "O0"] * Pt[, "O3"]) / (sum(Pt[, "O3"]) + epsilon)) / (max(gdm[, "O0"]) + epsilon)
  
  # r1 <- 1 - (2 * sum(Pt[, "O0"]) / sum(gdm[, "O0"]))
  # rho_1 <- ifelse(r1>= 0, r1, NA)
  rho_1 <- 1 - (2 * sum(Pt[, "O0"]) / (sum(gdm[, "O0"])))
  rho_2 <- 1 - (sum(Pt[, "O2"] * (1 - Pt[, "O3"])) / sum(Pt[, "O1"] * (1 - Pt[, "O3"])))

  rho_3 = (sum(gdm[, "O1"] * Pt[, "O1"] * (1 - Pt[, "O2"]) * (1 - Pt[, "O3"])) /
             sum(Pt[, "O1"] * (1 - Pt[, "O2"]) * (1 - Pt[, "O3"]))) / max(gdm[, "O0"])
  rho_4 = sum(gdm[, "O2"]) / (sum(Pt[, "O2"]) * max(gdm[, "O2"]))
  rho_5 = (0.5 * cov(rank(gdm[, "O1"]), rank(gdm[, "O2"])) / (sd(rank(gdm[, "O1"])) * sd(rank(gdm[, "O2"]))) + 0.5)
  U2 <- ifelse(gdm[, "O2"] == 1, 1, 0)
  U3 <- ifelse(gdm[, "O3"] == 0, 1, 0)
  rho_6 = sum(U2 * U3) / sum(Pt[, "O2"])
  n_strings = count_distinct_strings(graph, which(U2 & U3))
  rho_7 = 1 - (n_strings / sum(U2 * U3))
  rho_8 = sum(gdm[, "O3"]) / (3 * sum(gdm[, "O2"]) + sum(gdm[, "O3"]))
  rho_9 = 1 - sum(Pt[, "O3"]) / sum(gdm[, "O3"])
  rho_10 = sum(Pt[, "O3"]) / sum(Pt[, "O0"])
  rho_11 = {numerator_rho_11 = sum(Pt[, "O3"] * U2); numerator_rho_11 / sum(Pt[, "O3"])}
  rho_12 = (sum(gdm[, "O0"] * Pt[, "O3"]) / sum(Pt[, "O3"])) / max(gdm[, "O0"])
  
  ggv <- c(rho_1, rho_2, rho_3, rho_4, rho_5, rho_6, rho_7, rho_8, rho_9, rho_10, rho_11, rho_12)

  return(ggv)
}


# Function to check connectivity and count distinct strings
count_distinct_strings <- function(g, intermediate_nodes) {
  distinct_strings_count <- 0
  visited <- rep(FALSE, igraph::vcount(g))
  
  # Check connectivity for each intermediate node
  for (node in intermediate_nodes) {
    if (!visited[node]) {
      visited[node] <- TRUE
      distinct_strings_count <- distinct_strings_count + 1
      
      # Explore connected intermediate nodes
      to_explore <- c(node)
      while (length(to_explore) > 0) {
        current_node <- to_explore[1]
        to_explore <- to_explore[-1]
        
        # Get all unvisited neighbors that are also intermediate nodes
        neighbors <- unlist(igraph::neighbors(g, current_node))
        unvisited_intermediate_neighbors <- neighbors[visited[neighbors] == FALSE & neighbors %in% intermediate_nodes]
        
        # Mark them as visited and add to the exploration list
        visited[unvisited_intermediate_neighbors] <- TRUE
        to_explore <- c(to_explore, unvisited_intermediate_neighbors)
      }
    }
  }
  
  return(distinct_strings_count)
}


#' @keywords internal
my.f1_score <- function(actual, predicted) {
if (!inherits(actual, "lgCMatrix") || !inherits(predicted, "lgCMatrix")) {
  stop("Matrices should be of class lgCMatrix")
}
  
 # Calculating TP, FP, and FN using sparse matrix operations
TP <- sum(predicted & actual)
FP <- sum(predicted & !actual)
FN <- sum(!predicted & actual)

# Calculate Precision and Recall
Precision <- ifelse(TP + FP > 0, TP / (TP + FP), 0)
Recall <- ifelse(TP + FN > 0, TP / (TP + FN), 0)

# Calculate F1 Score
f1 <- ifelse(Precision + Recall > 0, 2 * (Precision * Recall) / (Precision + Recall), 0)

return(f1)
}


#' @keywords internal
my.hamming <- function(estimated, actual) {
    hamming_distance <- sum(Matrix::tril(estimated) != Matrix::tril(actual))
    return(hamming_distance)
}


my.gcvec <- function(graph, method, orbind, five_node = FALSE, pseudo_count = FALSE, return_gcm = FALSE) {
  
  orbind <- orbind + 1
  if (length(orbind) < 2) stop("Only one orbit selected, need at least two to calculate graphlet correlations")
  if (five_node == FALSE && any(orbind > 15))   stop("Only 15 orbits, from 4-node graphlets, can be selected")
  if (!method %in% c("kendall", "spearman", "latentcor")) stop("Not supported correlation method is chosen!")
  nx2 <- .adj2elist(graph) # Transform adjacency matrix to nx2 edge matrix
  n <- length(orbind)
  if (ncol(nx2) < 1 || nrow(nx2) < 1) {
      return(rep(0, n*(n-1)/2)) # Return empty vector # Failsafe for empty graphs
  }

  p <- ncol(graph)
  if (five_node == TRUE) { gdm <- orca::count5(nx2)
    } else { gdm <- orca::count4(nx2) # redundant Graphlet Degree Matrix (gdm) px15
  } 
  
  ## expand missing nodes
  buffer <- matrix(0, nrow=p-nrow(gdm), ncol=ncol(gdm)) # Create empty set up
  gdm <- rbind(gdm, buffer) # non-redundant Graphlet Degree Matrix (gdm) px11
  ## warnings here are due to std dev == 0. This almost always occurs for a completely connected
  ## or completely empty graph and can be safely suppressed.
  
  # add one row of 1s to the orbind matrix to overcome std dev == 0 error problem 
  gdm <- rbind(gdm[,orbind],1) 
  
  if (pseudo_count == TRUE) {
    ## Add pseudo_count to orb_count
    gdm <- modify_orb_count(orb_count = gdm, pseudo_count_range = c(0, 0.1))
  } 

  if (method %in% c("kendall", "spearman")){
  #Then calculate the graphlet correlation matrix with method
  gcm <- suppressWarnings(cor(gdm, method = method))
  }
  
  else if (method == "latentcor") {
  gcm <- suppressMessages(latentcor::latentcor(gdm, method = "approx", use.nearPD = FALSE))
  gcm <- gcm$R
  }
  
  gcv <- gcm[upper.tri(gcm)] # Create a numeric vector of the upper triangle of gcm
  
  if (return_gcm == TRUE) {
    return(gcm)
  } else return(gcv)
}


modify_orb_count <- function(orb_count, pseudo_count_range = c(0, 0.1)) {
  # Validate the orbit_count_range input
  if (length(pseudo_count_range) != 2 || pseudo_count_range[1] >= pseudo_count_range[2]) {
    stop("pseudo_count_range must be a vector of two numbers, where the first is less than the second. 
         \n i.e. pseudo_count_range = c(0, 0.1)")
  }

  # Generate a random matrix with the same dimensions as orb_count
  random_matrix <- matrix(runif(nrow(orb_count) * ncol(orb_count), 
                               min = pseudo_count_range[1], 
                               max = pseudo_count_range[2]), 
                          nrow = nrow(orb_count), 
                          ncol = ncol(orb_count))
  
  # Apply conditional logic to add random noise only to the zero elements of orb_count
  modified_orb_count <- mapply(function(orb_elem, random_elem) {
                               if (orb_elem == 0) orb_elem + random_elem else orb_elem
                             }, orb_count, random_matrix)
  
  # Convert the modified_orb_count to a matrix and set the column names
  modified_orb_count_matrix <- matrix(modified_orb_count, nrow = nrow(orb_count), ncol = ncol(orb_count))
  colnames(modified_orb_count_matrix) <- colnames(orb_count)

  return(modified_orb_count_matrix)
}


my.gcd.stability <- function(premerge, prior_graph, rep.num, p, nlams, use_prior = FALSE, method, orbind, ...) { 
    est <- list()

    if (!method %in% c("kendall", "spearman", "latentcor")) {
        stop("Not supported correlation method chosen!")
    }


    if (use_prior) {
        gcv_true = my.gcvec(prior_graph, method = method, orbind = orbind, ...) # gcv for true_graph

        est$merge <- vector("list", nlams)
        for (i in 1:nlams) {
            lambda_distances <- numeric(rep.num)
            for (j in 1:rep.num) {
                gcv_sub <- premerge[[j]][[i]] # gcv of subsample j and lambda i
                lambda_distances[j] <- dist(rbind(gcv_sub, gcv_true))[[1]] # calculate gcd
            }
            est$merge[[i]] <- lambda_distances 
        }
    } else { 
        est$merge <- lapply(1:nlams, function(i) dist(t(sapply(1:rep.num, function(j) premerge[[j]][[i]])))) 
    }

    est$summary <- vector('numeric', nlams)
    for (i in 1:nlams) {
        est$summary[i] <- mean(est$merge[[i]]) # Fill summary: ith lambda = mean over all j subsamples 
    }

    return(est)
}

#########################################################################################################
######################################### Modified Pulsar Functions######################################
#########################################################################################################

#' @keywords internal
stars.stability <- function(premerge, stars.thresh, rep.num, p, merge=NULL) { 
    if (is.null(stars.thresh)) stars.thresh <- 0.1
    est <- list()


    # do.call(batchtools::reduceResults,
    #                  c(list(reg=reg, fun=starsaggfun), reduceargs))

    if (is.null(merge)) {
      est$merge <- lapply(premerge, function(x) Reduce("+", x)) # Like sum(), but can also used for adding matrices etc.
      # If merge is not provided, the function aggregates the premerge results to get a consolidated view of 
      #the model's performance across all subsamples.
      gc() # flush
    } else est$merge <- merge
    
    est$summary <- rep(0, length(est$merge)) # empty array

    for (i in 1:length(est$merge)) { # The function calculates the variability of model selection across subsamples
      est$merge[[i]] <- est$merge[[i]]/rep.num # Normalization: Now we have prob to observe a specific edge over subsamples
      est$summary[i] <- 4 * sum(est$merge[[i]] * (1 - est$merge[[i]])) / (p * (p - 1)) # Total edge variability measure
    }

    est$summary   <- cummax(est$summary)  # Monotonize variability
    est$opt.index <- .starsind(est$summary, stars.thresh) # Optimal index based on computed stability measures and threshold
    est$thresh    <- stars.thresh
    return(est)
}


#' @export
plot.pulsar <- function(x, scale=TRUE, invlam=FALSE, loglam=FALSE, legends=TRUE, show = NULL, ...) {
    .plot.pulsar(x, scale, invlam, loglam, legends, show)
    return(invisible())
}


#' @export
refit.pulsar <- function(obj, criterion) {
    .refit.pulsar(obj, criterion)
}


#' @keywords internal
.refit.pulsar <- function(obj, criterion) {
    est <- vector('list', 2)
    names(est) <- c('est', 'refit')
    fin <- getArgs(getCall(obj), getEnvir(obj))
    fin$criterion <- obj$criterion
    ## call est function on original dataset
    if (length(obj$est)) {
      est$est <- obj$est
    } else {
      est$est <- do.call(eval(fin$fun), c(fin$fargs, list(fin$data)))
    }

    if (missing(criterion)) criterion <- eval(fin$criterion)
    est$refit <- vector('list', length(criterion))
    names(est$refit) <- criterion
    for (crit in criterion) {
      optind <- obj[[crit]]$opt.index
      if (!is.null(optind)) {
        est$refit[[crit]] <- est$est$path[[optind]]
      } else {
        est$refit[[crit]] <- NULL
        if (crit %in% names(obj)) {
          message(paste('No optimal index selected for', crit, 'criterion', sep=" "))
        } else
          warning(paste('Unknown criterion', crit, sep=" "), call.=FALSE)
      }
    }

    ## TODO: if fun is null, get formal arg of obj
    est$fun <- obj$call$fun
    if (is.null(est$fun))
      est$fun <- formals(class(obj))$fun

    structure(est, class='pulsar.refit')
}

#' @keywords internal
getArgs <- function(call, envir=parent.frame()) {
    fin    <- lapply(call, eval, envir=envir)
    forms  <- formals(fin[[1]])
    iscall <- sapply(forms, class) == 'call'
    iscall <- iscall & !(names(forms) %in% c('regdir', 'regid'))
    forms[iscall] <- lapply(forms[iscall], eval)
    c(forms[!(names(forms) %in% names(fin))], fin)
}


#' @keywords internal
.plot.pulsar <- function(x, scale=TRUE, invlam=FALSE, loglam=FALSE, legends=TRUE, show = NULL) {
    fin  <- getArgs(getCall(x), getEnvir(x))
    lams <- fin$fargs$lambda
    xlab <- "lambda"
    if (invlam) {lams <- 1/lams ; xlab <- paste("1/", xlab, sep="")}
    if (loglam) {lams <- log(lams) ; xlab <- paste("log[ ", xlab, " ]", sep="")}

    nlam  <- length(lams)
    fin$criterion <- setdiff(out.p$criterion, c("oracle_f1", "oracle_hamming"))
    crits <- fin$criterion
    
    # Filter criteria based on 'show' parameter
    if (!is.null(show) && length(show) > 0) {
      # Directly filter criteria based on 'show' array
      crits <- crits[crits %in% show]
    }
    
    n <- length(crits)
    if (scale) {
        ylab <- "summary (scaled)"
        if ("stars" %in% crits)
            ymax <- max(x$stars$summary)
        else ymax <- 1
    } else {
        ylab <- "summary"
        ymax <- max(unlist(lapply(crits, function(c) x[[ c ]]$summary)))
    }

    yrange <- c(0, ymax)
    plot(lams, seq(yrange[1], yrange[2], length.out=nlam),
         xlab=xlab, ylab=ylab, type='n')
    if (!is.null(x$stars$lb.index)) {
        ilams <- 1:length(lams)
        range1 <- ilams < x$stars$ub.index
        range2 <- ilams > x$stars$lb.index
        range  <- !(range1 | range2)
        ccol   <- vector('numeric', n+1)
        ltys   <- vector('numeric', n+1)
        legs   <- vector('numeric', n+1)
    } else {
        range1 <- rep(FALSE, nlam) ; range2 <- range1
        range  <- !range1
        ccol   <- vector('numeric', n)
        ltys   <- vector('numeric', n)
        legs   <- vector('numeric', n)
    }

    i <- 1 ; lcol <- 1
    optcrits <- c() ; optcols <- c()
    for (cr in crits) {
        summs <- x[[ cr ]]$summary
        optind <- opt.index(x, cr)
        if (scale && cr != "stars") summs <- ymax*summs/max(summs)
        if (length(summs) == nlam) {
            points(lams[range],  summs[range],  type='b', col=lcol)
            points(lams[range1], summs[range1], type='b', col=lcol, lty=2)
            points(lams[range2], summs[range2], type='b', col=lcol, lty=2)
            optind2 <- optind

            if (any(range1 | range2)) {
                ccol[i:(i+1)] <- c(lcol,lcol)
                ltys[i:(i+1)] <- c(2,1)
                legs[i:(i+1)] <- c(paste("b-", cr, sep=""), cr)
                i <- i+1
            } else {
                ccol[i] <- lcol
                ltys[i] <- 1
                legs[i] <- cr
            }
        } else {
            points(lams[range], summs, type='b', col=lcol)
            optind2 <- optind-which(range)[1]+1
            ccol[i] <- lcol
            ltys[i] <- 1
            legs[i] <- cr
        }

        if (!is.null(optind)) {
            points(lams[optind], summs[optind2], type='p', cex=1.5, pch=16, col=lcol)
            optcrits <- c(optcrits, cr)
            optcols  <- c(optcols , lcol)
        }
        lcol <- lcol + 1 ; i <- i + 1
    }

    if (legends) {
      legend('bottomleft', legs, col=ccol, pch=1, lty=ltys, cex=0.7)
      if (length(optcrits) > 0) {
        #legend('left', optcrits, pch=16, col=optcols, cex=0.5, title="opt lambda")
      }
    }
}


#' @rdname print.pulsar
#' @export
print.batch.pulsar <- function(x, ...) {
    fin <- getArgs(getCall(x), getEnvir(x))
    cat("Mode: batch")
    .print.pulsar(x, fin)
}


#' @keywords internal
.print.pulsar <- function(x, fin) {
    if (fin$lb.stars) {
        cat("... bound index: lower ", x$stars$lb.index,
            ", upper ", x$stars$ub.index, "\n", sep="")
    } else cat("\n")
    cat("Path length:", length(fin$fargs$lambda), "\n")
    cat("Subsamples: ", fin$rep.num, "\n")
    cat("Graph dim:  ", ncol(fin$data), "\n")
    fin$criterion <- x$criterion # Adapt new criteria
    critext  <- ifelse(length(fin$criterion) > 1, "Criteria:", "Criterion:")
    critext2 <- lapply(fin$criterion, function(cr) {
        opt.ind <- x[[cr]]$opt.ind
        optext  <- ifelse(is.null(opt.ind), "",
          paste("... opt: index ", opt.ind, ", lambda ",
          signif(fin$fargs$lambda[opt.ind], 3), sep=""))
        paste("  ", cr, optext, sep="")
        })
    cat(critext, "\n", paste(critext2, collapse="\n"), "\n", sep="")
}


#' @export
get.opt.index <- function(obj, criterion="gcd", ...) {
    optind <- opt.index(obj, criterion)
    if (!is.null(optind)) optind
      if (startsWith(criterion, "gcd_") || startsWith(criterion, "ghust")) {
        gcdind <- which.min(getElement(obj, criterion)$summary)
        if (!is.null(obj$stars$ub.index)) {
          gcdind <- gcdind + obj$stars$ub.index - 1
        }
        #names(gcdind) <- criterion
        return(gcdind)
      }
}


#' @export
"opt.index<-" <- function(obj, criterion=names(value), value) {
    .pcheck(obj)
    fin <- getArgs(obj$call, obj$envir)
    .critcheck(obj, criterion)
    if (length(criterion) > 1) stop("Select one criterion")
    if (is.null(criterion)) stop("Select one criterion")
    if (!is.null(value)) {
      if (!is.numeric(value) || value < 1 || value > length(fin$fargs$lambda))
        stop('Index value must be positive int within range length of lambda path')
    }
    obj[[ criterion ]]$opt.index <- value
    obj
}

#########################################################################################################
################################## Unmodified Pulsar Functions ##########################################
#########################################################################################################

#' @keywords internal
.critcheck <- function(obj, criterion=NULL) {
    if (!(criterion %in% names(obj)))
        warning('desired criterion was not used in the pulsar run')
}


#' @export
opt.index <- function(obj, criterion='gcd') {
    .pcheck(obj)
    .critcheck(obj, criterion)
    getElement(obj, criterion)$opt.index
}


#' @keywords internal
.pcheck <- function(obj) {
    if (!inherits(obj, 'pulsar'))
        stop("obj must be pulsar output")
}


findConfFile <- function(name='') {
 ## if x is not a file
 ## look for config file using batchtools rules,
 ## otherwise, look in the pulsar system package

  conffile <- batchtools::findConfFile()
  if (!is.na(conffile)) return(conffile)

  if (checkmate::testFileExists(name, access = "r"))
    return(fs::path_real(name))

  ## append type to file extension for default config files
  if (nchar(name)==0) name <- '.R'
  else name <- paste0('.', tools::file_path_sans_ext(name), '.R')

  conffile <- fs::path_real(system.file('config',
                  sprintf('batchtools.conf%s', name), package='pulsar'))
  # }
  if (checkmate::testFileExists(conffile, access = "r")) return(conffile)
  else return(character(0))
}

#' @keywords internal
.lamcheck <- function(lams) {
    if (is.null(lams)) {
        stop(paste('Error: missing members in fargs:',
             paste(c('lambda')[c(is.null(lams))])))
    } else {
        if (!all(lams == cummin(lams)))
            warning("Are you sure you don't want the lambda path to be monotonically decreasing")
        if (length(lams) < 2)
            warning("Only 1 value of lambda is given. Are you sure you want to do model selection?")
    }
}

#' @keywords internal
.ratcheck <- function(subsample.ratio, n) {
    if (is.null(subsample.ratio)) {
        if (n > 144)
            return(10 * sqrt(n)/n)
        else
            return(0.8)
    } else return(subsample.ratio)
}

#' @keywords internal
.critcheck0 <- function(criterion, knowncrits) {
    if (!all(criterion %in% knowncrits)) {
       stop(paste('Unknown criterion', paste(criterion[!(criterion %in% knowncrits)],
                   collapse=", "), sep=": "))
    }
    starsdepend <- c("estrada", "sufficiency")
    if (any(starsdepend %in% knowncrits)) {
        if (any(starsdepend %in% criterion) && !("stars" %in% criterion)) {
             stop(paste('Criterion: ', paste(starsdepend[starsdepend %in% criterion],
                   collapse=", "), ' cannot be run unless stars is also a selected criterion', sep=""))
        }
    }

}


#' @keywords internal
.starsind <- function(summary, thresh, offset=1) {
  if(any(summary >= thresh)){
    return(max(which.max(summary >= thresh)[1] - offset, 1))
  } else {
    warning("Optimal lambda may be outside the supplied values")
    return(length(summary))
  }
}

#' @keywords internal
batchply <- function(data, estFun, fun, fargs, ind.sample, wkdir, regdir,
                     conffile, job.res) {
  reg <- batchtools::makeRegistry(file.dir=regdir, work.dir=wkdir,
                                  conf.file=findConfFile(conffile))
  args <- list(fargs=fargs, data=data, fun=fun)
  id   <- batchtools::batchMap(estFun, ind.sample, more.args=args, reg=reg)
  doneSub <- batchtools::submitJobs(reg=reg, resources=job.res)
  return(list(reg=reg, id=id))
}

#' @keywords internal
.adj2elist <- function(G) {
    if (inherits(G, "sparseMatrix")) {
        G <- Matrix::triu(G, k=1)
        index_i_j <- Matrix::mat2triplet(G)[1:2]
        return(as.data.frame(index_i_j))
    } else {
        p <- ncol(G)
        return(arrayInd(which(as.logical(triu(G))), c(p,p)))
    }
}


```













