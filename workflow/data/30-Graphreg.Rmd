---
title: "30-my_batch_pulsar"
output: github_document
---

## my.batch.pulsar function
```{r}

## To Do List:
# Die N mal lambda_k graphs existieren nicht, wenn lb and ub == TRUE. Was existiert ist eine Liste mit N = 2 subsample dann N subsample f√ºr den regulierten Pfad und dann wieder N subsample.

Graphreg <- function(data, fun = huge::huge, fargs=list(),
                    criterion = c("stars"), thresh = 0.05, subsample.ratio = NULL,
                    lb.stars=FALSE, ub.stars=FALSE, rep.num = 20, seed=NULL,
                    wkdir=getwd(), regdir=NA, init="init", conffile='',
                    job.res=list(), cleanup=FALSE, refit = TRUE, 
                    prior_graph = NULL, method = c("spearman"), orbind = c(0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11),
                    use_pseudo_count = FALSE, five_node = FALSE) {

    if (!requireNamespace('batchtools', quietly=TRUE)) {
        stop("'batchtools' package required to run 'batch.pulsar'")
    }
    gcinfo(FALSE)
    if (!is.na(regdir) && file.exists(regdir)) {
        stop('Registry directory already exists')
    }
    
    n <- nrow(data)
    p <- ncol(data)
    knowncrits <- c("stars", "gcd", "gcd_prior")
    .lamcheck(fargs$lambda)
    .critcheck0(criterion, knowncrits)
    subsample.ratio <- .ratcheck(subsample.ratio, n)
    nlams <- length(fargs$lambda)
    conffile <- findConfFile(conffile)
    lambda_full <- fargs$lambda

    if (!is.null(seed)) set.seed(seed)
    ind.sample <- replicate(rep.num, sample(c(1:n), floor(n * subsample.ratio), replace = FALSE), simplify = FALSE)
    
    if (refit) {
        tmp <- 1L:n
        attr(tmp, 'full') <- TRUE
        ind.sample <- c(list(tmp), ind.sample)
    }
    if (!is.null(seed)) set.seed(NULL)

    estFun <- function(ind.sample, fargs, data, fun) {
        tmp <- do.call(fun, c(fargs, list(data[ind.sample,])))
        if (!('path' %in% names(tmp))) {
            stop('Error: expected data structure with \'path\' member')
        }
        if (isTRUE(attr(ind.sample, 'full'))) {
            return(tmp)
        } else {
            return(tmp$path)
        }
    }

    est <- list()
    reduceargs <- list()
    reduceargs2 <- list()
    reduceGCDargs <- list()
    reduceGCDargs_pseudo <- list()
    lb.gcdpremerge <- list()
    lb.gcdpremerge_pseudo <- list()
  
    
    if (lb.stars) {
        if (!("stars" %in% criterion)) {
            stop('Lower/Upper bound method must be used with StARS')
        }
        minN <- 2 + refit # minimum number of subsamples for a meaningful StARS computation
        if (!is.na(regdir)) regdir <- paste(regdir, init, sep = "_")
    } else {
        minN <- rep.num + refit # minimum number of subsamples is set to the number of repetitions
    }
    
    ## Analysing if lb.stars == TRUE: First 2 subsample + refit, if lb.stars == FALSE: All subsamples + refit
    isamp <- ind.sample[1:minN] # selects the first minN subsamples # ind.sample is a list of indices for subsampling the data
    out <- batchply(data, estFun, fun, fargs, isamp, wkdir, regdir, conffile, job.res) 
    reg <- out$reg # extract the registry object
    id <- out$id # and job ids from the output of batchply. # manage and track the submitted batch jobs.
    doneRun <- batchtools::waitForJobs(reg = reg, id) # waits for all submitted jobs to finish.
    jdone <- batchtools::findDone(reg = reg, id) # Identifies which jobs have completed successfully.
    pulsar.jobs <- intersect((1 + refit):minN, jdone$job.id) # ids of jobs successfully completed among initially submitted jobs.

    if (refit) { #block checks if there is a need to refit the model using the full dataset (not just subsamples).
        fullmodel <- batchtools::loadResult(id = 1, reg = reg) # If refit is TRUE, loads the result of the full dataset fit.
        minN <- minN - 1L # Adjusts the count of the number of subsamples by subtracting one, accounting for the full dataset fit.
    } else {
        fullmodel <- NULL #  indicating that no full dataset fit was performed.
    }
    
    ## Merge Function Stars
    #starsaggfun <- function(res, aggr) lapply(1:length(aggr), function(i) aggr[[i]] + res[[i]])
    # This is a custom function defined to aggregate the results of the subsampled analyses.
    
    ## Premerge Function Stars
    starsaggfun <- function(res, aggr) {
      if (is.null(aggr)) {
        # If aggr is NULL (first call), initialize it as a list of lists
        aggr <- vector("list", length(res))
        for (i in seq_along(aggr)) {
          aggr[[i]] <- list()
        }
      }
      
      # For each lambda, append the res to the corresponding list in aggr
      for (i in seq_along(res)) {
        aggr[[i]] <- append(aggr[[i]], res[[i]])
      }
  
      return(aggr)
    }
    
    
    if (lb.stars) {
        est$init.reg <- reg # Store the registry and job IDs.
        est$init.id <- id

        if (!doneRun) {
            stop('Errors in batch jobs for computing initial stability')
        }
        
        # collect initial results
        lb.starspremerge <- batchtools::reduceResults(reg = reg, ids = pulsar.jobs, fun = starsaggfun)
        lb.est <- stars.stability(premerge = lb.starspremerge, thresh, minN, p, merge = NULL)
        est$lb.starspremerge <- lb.starspremerge

        # Calculates the stability of the lower bound estimate using the aggregated results.
        #lb.est <- stars.stability(NULL, thresh, minN, p, lb.starsmerge) 
        gc(FALSE)
        

        # Collect initial gcd results (We first compute only two subsamples and then the leftover N-2 subsamples later on)
        if ('gcd' %in% criterion || 'gcd_prior' %in% criterion) {

            for (meth in method) {
              
              if (use_pseudo_count == TRUE) {
                
                # Gather GCV for pseudo
                aggfun <- function(res, ...) {
                    lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind, five_node = five_node,
                                                     pseudo_count = TRUE, ...))
                }
                
                lb.gcdpremerge_pseudo[[meth]] <- do.call(batchtools::reduceResultsList,
                                                       c(list(reg = reg, ids = pulsar.jobs, fun = aggfun), reduceGCDargs_pseudo))
                
              }
              
              
              # Gather GCV 
              aggfun <- function(res, ...) {
                  lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind, five_node = five_node, ...))
              }
      
              # Processing and gathering results
              lb.gcdpremerge[[meth]] <- do.call(batchtools::reduceResultsList,
                                                     c(list(reg = reg, ids = pulsar.jobs, fun = aggfun), reduceGCDargs))
              
            }
        }
        

        if (cleanup) unlink(reg$file.dir, recursive = TRUE) # deletes the temporary files created during the batch job execution.
        if (lb.est$opt.index == 1) {
            warning("Accurate lower bound could not be determined with the first 2 subsamples")
        }
        
        # upper bound is determined by equivalent of maximum entropy of Poisson Binomial
        if (ub.stars) { # This block calculates the upper bound index for lambda selection, based on the variability of the results.
            pmean <- sapply(lb.est$merge, function(x) sum(x) / (p * (p - 1))) # calculates the mean probability of edge inclusion.
            ub.summary <- cummax(4 * pmean * (1 - pmean)) # Determine the index at which the variability 
            tmpub <- .starsind(ub.summary, thresh, 1) # of results is below the threshold.
            ub.index <- if (any(ub.summary == 0)) { # Sets the index for the upper bound.
                max(tmpub, max(which(ub.summary == 0)) + 1)
            } else {
                max(tmpub, 1)
            }
        } else {
            ub.index <- 1
        }
        
        # Adjusts the lambda path to be within the bounds
        fargs$lambda <- fargs$lambda[ub.index:lb.est$opt.index] 
        nlams <- length(fargs$lambda)
        # Prepare arguments for reducing results in the subsequent batch jobs
        reduceargs <- list(init = lb.starspremerge[ub.index:lb.est$opt.index])
        
        #######
        est$reduceargs <- reduceargs
        ########
       
  
        # If lb.stars was set to TRUE, create now the reduction arguments for gcd
        if ('gcd' %in% criterion || 'gcd_prior' %in% criterion) { 
        
            for (meth in method) {
              
              if (use_pseudo_count == TRUE) {
                # Create Pseudo GCV reduceGCDargs for the current method
                reduceGCDargs_pseudo[[meth]] <- list(init = lapply(lb.gcdpremerge_pseudo[[meth]], 
                                                                function(gcdpm) gcdpm[ub.index:lb.est$opt.index]))
              }
              
              # Create GCV reduceGCDargs for the current method
              reduceGCDargs[[meth]] <- list(init = lapply(lb.gcdpremerge[[meth]], 
                                                              function(gcdpm) gcdpm[ub.index:lb.est$opt.index]))
            }
        }

        
        regdir <- gsub(paste("_", init, sep = ""), "", regdir)
        isamp <- ind.sample[-(1:minN)] # First minN subsamples were already processed, and the remaining ones are to be handled now.
        out <- batchply(data, estFun, fun, fargs, isamp, wkdir, regdir, conffile, job.res) 
        # batchply function is called to submit batch jobs for processing
        reg <- out$reg
        id <- out$id
        doneRun <- batchtools::waitForJobs(reg = reg, id)
        jdone <- batchtools::findDone(reg = reg, id)
        pulsar.jobs <- intersect((1 + refit):rep.num, jdone$job.id)
    }

    rep.num <- length(pulsar.jobs)
    if (lb.stars) rep.num <- rep.num + minN
    if (!doneRun) {
        warning(paste("Only", length(jdone), "jobs completed... proceeding anyway"))
    }
    
    updated_criteria <- list()

    for (i in 1:length(criterion)) {
        crit <- criterion[i]
        
        if (crit == "stars") {
          
            starspremerge <- do.call(batchtools::reduceResults,
                                  c(list(reg = reg, ids = pulsar.jobs, fun = starsaggfun), reduceargs))
            
            #est$stars <- stars.stability(premerge = NULL, thresh, rep.num, p, merge = starsmerge)
            est$stars <- stars.stability(premerge = starspremerge, thresh, rep.num, p, merge = NULL)
            est$starspremerge <- starspremerge
        }
        
        # Actual calculation of N-2 graphlet correlation distance (gcd)
        if (crit == "gcd" || crit == "gcd_prior") {
          
            for (meth in method) {
              
              if (use_pseudo_count == TRUE) {
                
                # Update criterion to include new methods
                new_criterion_name <- if (crit == "gcd") {
                    paste("gcd_pseudo", meth, sep = "_")
                } else {
                    paste("gcd_prior_pseudo", meth, sep = "_")
                }
                updated_criteria <- c(updated_criteria, new_criterion_name)
                
                
                # Gather GCV for Pseudo
                aggfun <- function(res, ...) {
                  lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind, five_node = five_node,
                                                         pseudo_count = TRUE, ...))
                }
                
                # Processing and gathering gcv results
                gcdpremerge_pseudo <- c(reduceGCDargs_pseudo[[meth]]$init,
                                 batchtools::reduceResultsList(reg = reg, ids = pulsar.jobs, fun = aggfun))
                
                
        
                if (crit == "gcd") {
                    est[[paste("gcd_pseudo", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge_pseudo, 
                                                        thresh, rep.num, p, nlams, prior_graph = prior_graph, 
                                                        use_prior = FALSE, method = meth, orbind = orbind, five_node = five_node)
                    #est[[paste("gcdpremerge_pseudo", meth, sep = "_")]] <- gcdpremerge_pseudo
                }
            
                if (crit == "gcd_prior") {
                    est[[paste("gcd_prior_pseudo", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge_pseudo, 
                                                        thresh, rep.num, p, nlams, prior_graph = prior_graph, 
                                                        use_prior = TRUE, method = meth, orbind = orbind, five_node = five_node)
                    #est[[paste("gcdpremerge_prior_pseudo", meth, sep = "_")]] <- gcdpremerge_pseudo
                }
              }
                
              # Update criterion to include new methods
              new_criterion_name <- if (crit == "gcd") {
                  paste("gcd", meth, sep = "_")
              } else {
                  paste("gcd_prior", meth, sep = "_")
              }
              updated_criteria <- c(updated_criteria, new_criterion_name)

              
              # Gather GCV
              aggfun <- function(res, ...) {
                      lapply(res, function(x) my.gcvec(x, method = meth, orbind = orbind, five_node = five_node, ...))
              }
              
              # Processing and gathering results
              gcdpremerge <- c(reduceGCDargs[[meth]]$init,
                               batchtools::reduceResultsList(reg = reg, ids = pulsar.jobs, fun = aggfun))
              
              
      
              if (crit == "gcd") {
                  est[[paste("gcd", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge, 
                                                      thresh, rep.num, p, nlams, prior_graph = prior_graph, 
                                                      use_prior = FALSE, method = meth, orbind = orbind, five_node = five_node)
                  #est[[paste("gcdpremerge", meth, sep = "_")]] <- gcdpremerge
              }
          
              else if (crit == "gcd_prior") {
                  est[[paste("gcd_prior", meth, sep = "_")]] <- my.gcd.stability(premerge = gcdpremerge, 
                                                      thresh, rep.num, p, nlams, prior_graph = prior_graph, 
                                                      use_prior = TRUE, method = meth, orbind = orbind, five_node = five_node)
                  #est[[paste("gcdpremerge_prior", meth, sep = "_")]] <- gcdpremerge
              }
              
            }
        }
    }
    
    if (lb.stars) {
      ## split indices of init and full stars estimate
      pind <- ub.index:lb.est$opt.index
      pinv <- setdiff(1:length(lb.est$summary), pind)
      ## stitch back together init and full stars summaries
      tmpsumm       <- vector('numeric', length(lb.est$summary))
      tmpsumm[pinv] <- lb.est$summary[pinv]
      tmpsumm[pind] <- est$stars$summary
      est$stars$summary <- tmpsumm
      ## stitch back together init and full stars merges 
      tmpmerg <- vector('list', length(lb.est$summary))
      tmpmerg[pinv]   <- lb.est$merge[pinv]
      tmpmerg[pind]   <- est$stars$merge
      est$stars$merge <- tmpmerg
      ## record stars-related indices
      est$stars$lb.index  <- lb.est$opt.index
      est$stars$ub.index  <- ub.index
      est$stars$opt.index <- est$stars$opt.index + ub.index - 1
      
      ## Additional metrics
      est$additional$ind_bound <- pind
      est$additional$ind_rest <- pinv
      est$additional$lb.lambda <- round(lambda_full[lb.est$opt.index], 3)
      est$additional$ub.lambda <- round(lambda_full[ub.index], 3)
      stars_lambda <- round(lambda_full[est$stars$opt.index], 3)
      est$additional$gap_b <- abs(est$additional$ub.lambda - est$additional$lb.lambda)
      est$additional$gap_beta <- abs(stars_lambda - est$additional$lb.lambda)
      est$additional$lambda_bound <- fargs$lambda
      
      ## stitch back together init and full GCD summaries
      # for (crit in criterion) {
      #   if (startsWith(crit, "gcd")) {
      #     tmpsumm <- vector('numeric', length(lb.est[[crit]]$summary))
      #     tmpsumm[pinv] <- lb.est[[crit]]$summary[pinv]
      #     tmpsumm[pind] <- est[[crit]]$summary
      #     est[[crit]]$summary <- tmpsumm
      #   }
      # }
    }
    
    ## Full lambda path
    est$additional$lambda_full <- lambda_full
    

    ## Update criterion vector 
    criterion <- unique(c(criterion, updated_criteria))
    criterion <- setdiff(criterion, c("gcd", "gcd_prior"))
    est$criterion <- criterion
    # Naming new criterion description according to cirterion
    for (crit in criterion) {
      est[[crit]]$criterion <- crit
    }
    
    ## Compute and set optimal indices directly (excluding StARS)
    for (crit in criterion) {
      if (startsWith(crit, "gcd")) {
        gcdind <- which.min(est[[crit]]$summary)

        if (lb.stars){
          gcdind <- gcdind + est$stars$ub.index - 1
        }
        est[[crit]]$opt.index <- gcdind
      }

      ## Iterate over each criterion and store the corresponding optimal lambda value
      est[[crit]]$opt.lambda <- signif(lambda_full[est[[crit]]$opt.index], 3)
    }


    ## Refit section
    if (refit == TRUE) {

      # Refit each criterion with optimal index
      for (crit in criterion) {
        opt_ind <- est[[crit]]$opt.index
        if (!is.null(opt_ind)) {
          est[[crit]]$refit <- fullmodel$path[[opt_ind]]
        } else {
          est[[crit]]$refit <- NULL
        }
      }

      ## Determine adjacency matrices for full lambda path
      for (crit in criterion) {
          if (startsWith(crit, "gcd")) {
              est[[crit]]$all_adj <- list()
              for (i in seq_along(fargs$lambda)) {
                  gcdinds <- which(est[[crit]]$summary == est[[crit]]$summary[[i]])
                  if (lb.stars) {
                    gcdinds <- gcdinds + est$stars$ub.index - 1
                  }
                  valid_gcdind <- NULL
                  for (gcdind in gcdinds) {
                      if (!is.null(gcdind) && gcdind > 0 && gcdind <= length(fullmodel$path)) {
                          valid_gcdind <- gcdind
                          break
                      }
                  }

                  if (!is.null(valid_gcdind)) {
                      estim <- fullmodel$path[[valid_gcdind]]
                      est[[crit]]$all_adj[[i]] <- estim
                  } else {
                      est[[crit]]$all_adj[[i]] <- NULL
                  }
              }
          }
      }


      ## Determine F1 score and hamming distance
      if (!is.null(prior_graph)) {
          est$criterion <- c(criterion, c("oracle_f1", "oracle_hamming"))

          # Directly initialize as lists
          est$additional$hamming_dist <- list()
          est$additional$f1_score <- list()

          for (i in seq_along(fargs$lambda)) {
              gcdind <- NULL
              gcdind <- which(fargs$lambda == fargs$lambda[[i]])
              if (lb.stars) {
                gcdind <- gcdind + est$stars$ub.index - 1
              }
              
              if (!is.null(gcdind) && gcdind > 0 && gcdind <= length(fullmodel$path)) {
                  estim <- fullmodel$path[[gcdind]]
                  est$additional$hamming_dist[[i]] <- my.hamming(estimated = estim, actual = prior_graph)
                  est$additional$f1_score[[i]] <- my.f1_score(predicted = estim, actual = prior_graph)
              } else {
                  est$additional$hamming_dist[[i]] <- NULL
                  est$additional$f1_score[[i]] <- NULL
              }
          }

          # Define Oracle_f1 and Oracle_hamming
          gcdind <- which.max(est$additional$f1_score)
          if (lb.stars) {
            gcdind <- gcdind + est$stars$ub.index - 1
          }
          est$oracle_f1$opt.index <- gcdind
          est$oracle_f1$opt.lambda <- signif(lambda_full[est$oracle_f1$opt.index], 3)
          est$oracle_f1$refit <- fullmodel$path[[est$oracle_f1$opt.index]]
          est$oracle_f1$sparsity <- sum(est$oracle_f1$refit) / (p * (p - 1))

          gcdind <- which.min(est$additional$hamming_dist)
          if (lb.stars) {
            gcdind <- gcdind + est$stars$ub.index - 1
          }
          est$oracle_hamming$opt.index <- gcdind
          est$oracle_hamming$opt.lambda <- signif(lambda_full[est$oracle_hamming$opt.index], 3)
          est$oracle_hamming$refit <- fullmodel$path[[est$oracle_hamming$opt.index]]
          est$oracle_hamming$sparsity <- sum(est$oracle_hamming$refit) / (p * (p - 1))
      }

      # Calculate sparsity for criteria
      for (crit in criterion) {
        est[[crit]]$sparsity <- sum(est[[crit]]$refit) / (p * (p - 1))
      }

      # Determine GCMs for optimal estimate
      for(crit in criterion) {
        if (startsWith(crit, "gcd")) {

          count <- FALSE
          # Determine if 'pseudo' is part of the name
          if(grepl("pseudo", crit)) {
            count <-  TRUE
          }

          meth <- c("spearman")
          if(grepl("kendall", crit)) {
            meth <- c("kendall")
          }
          else if(grepl("latentcor", crit)) {
             meth <- c("latentcor")
          }

          # Apply function with the dynamically determined arguments
          graph <- est[[crit]][["refit"]]
          est[[crit]]$gcm <- my.gcvec(graph = graph, method = meth, pseudo_count = count,
                                        orbind = orbind, return_gcm = TRUE)
        }
      }
    }
    
    if (cleanup) unlink(reg$file.dir, recursive = TRUE)

    est$id <- id
    est$reg <- reg
    est$call <- match.call()
    est$est <- fullmodel
    est$envir <- parent.frame()


    print("Completed batch.pulsar function.")
    return(structure(est, class = c("batch.pulsar", "pulsar")))
}





#########################################################################################################



#' @export
get.opt.index <- function(obj, criterion="gcd", ...) {
    optind <- opt.index(obj, criterion)
    if (!is.null(optind)) optind
      if (startsWith(criterion, "gcd_")) {
        gcdind <- which.min(getElement(obj, criterion)$summary)
        if (!is.null(obj$stars$ub.index)) {
          gcdind <- gcdind + obj$stars$ub.index - 1
        }
        #names(gcdind) <- criterion
        return(gcdind)
      }
}

#' @export
opt.index <- function(obj, criterion='gcd') {
    .pcheck(obj)
    .critcheck(obj, criterion)
    getElement(obj, criterion)$opt.index
}


#' @keywords internal
.pcheck <- function(obj) {
    if (!inherits(obj, 'pulsar'))
        stop("obj must be pulsar output")
}

#' @keywords internal
.critcheck <- function(obj, criterion=NULL) {
    if (!(criterion %in% names(obj)))
        warning('desired criterion was not used in the pulsar run')
}


#' @export
"opt.index<-" <- function(obj, criterion=names(value), value) {
    .pcheck(obj)
    fin <- getArgs(obj$call, obj$envir)
    .critcheck(obj, criterion)
    if (length(criterion) > 1) stop("Select one criterion")
    if (is.null(criterion)) stop("Select one criterion")
    if (!is.null(value)) {
      if (!is.numeric(value) || value < 1 || value > length(fin$fargs$lambda))
        stop('Index value must be positive int within range length of lambda path')
    }
    obj[[ criterion ]]$opt.index <- value
    obj
}


######################################################################################################

#' @export
refit.pulsar <- function(obj, criterion) {
    .refit.pulsar(obj, criterion)
}

#' @keywords internal
.refit.pulsar <- function(obj, criterion) {
    est <- vector('list', 2)
    names(est) <- c('est', 'refit')
    fin <- getArgs(getCall(obj), getEnvir(obj))
    fin$criterion <- obj$criterion
    ## call est function on original dataset
    if (length(obj$est)) {
      est$est <- obj$est
    } else {
      est$est <- do.call(eval(fin$fun), c(fin$fargs, list(fin$data)))
    }

    if (missing(criterion)) criterion <- eval(fin$criterion)
    est$refit <- vector('list', length(criterion))
    names(est$refit) <- criterion
    for (crit in criterion) {
      optind <- obj[[crit]]$opt.index
      if (!is.null(optind)) {
        est$refit[[crit]] <- est$est$path[[optind]]
      } else {
        est$refit[[crit]] <- NULL
        if (crit %in% names(obj)) {
          message(paste('No optimal index selected for', crit, 'criterion', sep=" "))
        } else
          warning(paste('Unknown criterion', crit, sep=" "), call.=FALSE)
      }
    }

    ## TODO: if fun is null, get formal arg of obj
    est$fun <- obj$call$fun
    if (is.null(est$fun))
      est$fun <- formals(class(obj))$fun

    structure(est, class='pulsar.refit')
}

#' @keywords internal
getArgs <- function(call, envir=parent.frame()) {
    fin    <- lapply(call, eval, envir=envir)
    forms  <- formals(fin[[1]])
    iscall <- sapply(forms, class) == 'call'
    iscall <- iscall & !(names(forms) %in% c('regdir', 'regid'))
    forms[iscall] <- lapply(forms[iscall], eval)
    c(forms[!(names(forms) %in% names(fin))], fin)
}

#####################################################################################################

#F1-Score as criterium for Oracle

#' @keywords internal
my.f1_score <- function(actual, predicted) {
if (!inherits(actual, "lgCMatrix") || !inherits(predicted, "lgCMatrix")) {
  stop("Matrices should be of class lgCMatrix")
}
  
 # Calculating TP, FP, and FN using sparse matrix operations
TP <- sum(predicted & actual)
FP <- sum(predicted & !actual)
FN <- sum(!predicted & actual)

# Calculate Precision and Recall
Precision <- ifelse(TP + FP > 0, TP / (TP + FP), 0)
Recall <- ifelse(TP + FN > 0, TP / (TP + FN), 0)

# Calculate F1 Score
f1 <- ifelse(Precision + Recall > 0, 2 * (Precision * Recall) / (Precision + Recall), 0)

return(f1)
}

#######################################################
# Function to calculate F1-score and Hamming distance

#' @keywords internal
my.hamming <- function(estimated, actual) {
    hamming_distance <- sum(Matrix::tril(estimated) != Matrix::tril(actual))
    return(hamming_distance)
}


#########################################################################################################

#' @rdname print.pulsar
#' @export
print.batch.pulsar <- function(x, ...) {
    fin <- getArgs(getCall(x), getEnvir(x))
    cat("Mode: batch")
    .print.pulsar(x, fin)
}

#' @keywords internal
.print.pulsar <- function(x, fin) {
    if (fin$lb.stars) {
        cat("... bound index: lower ", x$stars$lb.index,
            ", upper ", x$stars$ub.index, "\n", sep="")
    } else cat("\n")
    cat("Path length:", length(fin$fargs$lambda), "\n")
    cat("Subsamples: ", fin$rep.num, "\n")
    cat("Graph dim:  ", ncol(fin$data), "\n")
    fin$criterion <- x$criterion # Adapt new criteria
    critext  <- ifelse(length(fin$criterion) > 1, "Criteria:", "Criterion:")
    critext2 <- lapply(fin$criterion, function(cr) {
        opt.ind <- x[[cr]]$opt.ind
        optext  <- ifelse(is.null(opt.ind), "",
          paste("... opt: index ", opt.ind, ", lambda ",
          signif(fin$fargs$lambda[opt.ind], 3), sep=""))
        paste("  ", cr, optext, sep="")
        })
    cat(critext, "\n", paste(critext2, collapse="\n"), "\n", sep="")
}

##################################################

my.gcvec <- function(graph, method, orbind, five_node = FALSE, pseudo_count = FALSE, return_gcm = FALSE) {
  
  orbind <- orbind + 1
  if (length(orbind) < 2) stop("Only one orbit selected, need at least two to calculate graphlet correlations")
  if (any(orbind > 15))   stop("Only 15 orbits, from 4-node graphlets, can be selected")
  if (!method %in% c("kendall", "spearman", "latentcor")) stop("Not supported correlation method is chosen!")
  nx2 <- .adj2elist(graph) # Transform adjacency matrix to nx2 edge matrix
  n <- length(orbind)
  if (ncol(nx2) < 1 || nrow(nx2) < 1) {
      return(rep(0, n*(n-1)/2)) # Return empty vector
  }

  p <- ncol(graph)
  if (five_node == TRUE) { gdm <- orca::count5(nx2)
    } else { gdm <- orca::count4(nx2) # redundant Graphlet Degree Matrix (gdm) px15
  } 
  
  ## expand missing nodes
  buffer <- matrix(0, nrow=p-nrow(gdm), ncol=ncol(gdm)) # Create empty set up
  gdm <- rbind(gdm, buffer) # non-redundant Graphlet Degree Matrix (gdm) px11
  ## warnings here are due to std dev == 0. This almost always occurs for a completely connected
  ## or completely empty graph and can be safely suppressed.
  
  # add one row of 1s to the orbind matrix to overcome std dev == 0 error problem 
  gdm <- rbind(gdm[,orbind],1) 
  
  if (pseudo_count == TRUE) {
    ## Add pseudo_count to orb_count
    gdm <- modify_orb_count(orb_count = gdm, pseudo_count_range = c(0, 0.1))
  } 

  if (method %in% c("kendall", "spearman")){
  #Then calculate the graphlet correlation matrix with method
  gcm <- suppressWarnings(cor(gdm, method = method))
  }
  
  else if (method == "latentcor") {
  gcm <- suppressMessages(latentcor::latentcor(gdm, method = "approx", use.nearPD = FALSE))
  gcm <- gcm$R
  }
  
  gcv <- gcm[upper.tri(gcm)] # Create a numeric vector of the upper triangle of gcm
  
  if (return_gcm == TRUE) {
    return(gcm)
  } else return(gcv)
}


#################

modify_orb_count <- function(orb_count, pseudo_count_range = c(0, 0.1)) {
  # Validate the orbit_count_range input
  if (length(pseudo_count_range) != 2 || pseudo_count_range[1] >= pseudo_count_range[2]) {
    stop("pseudo_count_range must be a vector of two numbers, where the first is less than the second. 
         \n i.e. pseudo_count_range = c(0, 0.1)")
  }

  # Generate a random matrix with the same dimensions as orb_count
  random_matrix <- matrix(runif(nrow(orb_count) * ncol(orb_count), 
                               min = pseudo_count_range[1], 
                               max = pseudo_count_range[2]), 
                          nrow = nrow(orb_count), 
                          ncol = ncol(orb_count))
  
  # Apply conditional logic to add random noise only to the zero elements of orb_count
  modified_orb_count <- mapply(function(orb_elem, random_elem) {
                               if (orb_elem == 0) orb_elem + random_elem else orb_elem
                             }, orb_count, random_matrix)
  
  # Convert the modified_orb_count to a matrix and set the column names
  modified_orb_count_matrix <- matrix(modified_orb_count, nrow = nrow(orb_count), ncol = ncol(orb_count))
  colnames(modified_orb_count_matrix) <- colnames(orb_count)

  return(modified_orb_count_matrix)
}


###################################################### 

my.gcd.stability <- function(premerge, prior_graph, thresh, rep.num, p, nlams, use_prior = FALSE, method, orbind, five_node, ...) { 
    est <- list()

    if (!method %in% c("kendall", "spearman", "latentcor")) {
        stop("Not supported correlation method chosen!")
    }


    if (use_prior) {
        gcv_true = my.gcvec(prior_graph, method = method, orbind = orbind, five_node = five_node, ...) # gcv for true_graph

        est$merge <- vector("list", nlams)
        for (i in 1:nlams) {
            lambda_distances <- numeric(rep.num)
            for (j in 1:rep.num) {
                gcv_sub <- premerge[[j]][[i]] # gcv of subsample j and lambda i
                lambda_distances[j] <- dist(rbind(gcv_sub, gcv_true))[[1]] # calculate gcd
            }
            est$merge[[i]] <- lambda_distances 
        }
    } else { 
        est$merge <- lapply(1:nlams, function(i) dist(t(sapply(1:rep.num, function(j) premerge[[j]][[i]])))) 
    }

    est$summary <- vector('numeric', nlams)
    for (i in 1:nlams) {
        est$summary[i] <- mean(est$merge[[i]]) # Fill summary: ith lambda = mean over all j subsamples 
    }

    return(est)
}

#########################################################################


library(batchtools)
library(pulsar)

#' @keywords internal
stars.stability <- function(premerge, stars.thresh, rep.num, p, merge=NULL) { 
    if (is.null(stars.thresh)) stars.thresh <- 0.1
    est <- list()


    # do.call(batchtools::reduceResults,
    #                  c(list(reg=reg, fun=starsaggfun), reduceargs))

    if (is.null(merge)) {
      est$merge <- lapply(premerge, function(x) Reduce("+", x)) # Like sum(), but can also used for adding matrices etc.
      # If merge is not provided, the function aggregates the premerge results to get a consolidated view of 
      #the model's performance across all subsamples.
      gc() # flush
    } else est$merge <- merge
    
    est$summary <- rep(0, length(est$merge)) # empty array

    for (i in 1:length(est$merge)) { # The function calculates the variability of model selection across subsamples
      est$merge[[i]] <- est$merge[[i]]/rep.num # Normalization: Now we have prob to observe a specific edge over subsamples
      est$summary[i] <- 4 * sum(est$merge[[i]] * (1 - est$merge[[i]])) / (p * (p - 1)) # Total edge variability measure
    }

    est$summary   <- cummax(est$summary)  # Monotonize variability
    est$opt.index <- .starsind(est$summary, stars.thresh) # Optimal index based on computed stability measures and threshold
    est$thresh    <- stars.thresh
    return(est)
}


#######################

findConfFile <- function(name='') {
 ## if x is not a file
 ## look for config file using batchtools rules,
 ## otherwise, look in the pulsar system package

  conffile <- batchtools::findConfFile()
  if (!is.na(conffile)) return(conffile)

  if (checkmate::testFileExists(name, access = "r"))
    return(fs::path_real(name))

  ## append type to file extension for default config files
  if (nchar(name)==0) name <- '.R'
  else name <- paste0('.', tools::file_path_sans_ext(name), '.R')

  conffile <- fs::path_real(system.file('config',
                  sprintf('batchtools.conf%s', name), package='pulsar'))
  # }
  if (checkmate::testFileExists(conffile, access = "r")) return(conffile)
  else return(character(0))
}

#' @keywords internal
.lamcheck <- function(lams) {
    if (is.null(lams)) {
        stop(paste('Error: missing members in fargs:',
             paste(c('lambda')[c(is.null(lams))])))
    } else {
        if (!all(lams == cummin(lams)))
            warning("Are you sure you don't want the lambda path to be monotonically decreasing")
        if (length(lams) < 2)
            warning("Only 1 value of lambda is given. Are you sure you want to do model selection?")
    }
}

#' @keywords internal
.ratcheck <- function(subsample.ratio, n) {
    if (is.null(subsample.ratio)) {
        if (n > 144)
            return(10 * sqrt(n)/n)
        else
            return(0.8)
    } else return(subsample.ratio)
}

#' @keywords internal
.critcheck0 <- function(criterion, knowncrits) {
    if (!all(criterion %in% knowncrits)) {
       stop(paste('Unknown criterion', paste(criterion[!(criterion %in% knowncrits)],
                   collapse=", "), sep=": "))
    }
    starsdepend <- c("estrada", "sufficiency")
    if (any(starsdepend %in% knowncrits)) {
        if (any(starsdepend %in% criterion) && !("stars" %in% criterion)) {
             stop(paste('Criterion: ', paste(starsdepend[starsdepend %in% criterion],
                   collapse=", "), ' cannot be run unless stars is also a selected criterion', sep=""))
        }
    }

}


#' @keywords internal
.starsind <- function(summary, thresh, offset=1) {
  if(any(summary >= thresh)){
    return(max(which.max(summary >= thresh)[1] - offset, 1))
  } else {
    warning("Optimal lambda may be outside the supplied values")
    return(length(summary))
  }
}

#' @keywords internal
batchply <- function(data, estFun, fun, fargs, ind.sample, wkdir, regdir,
                     conffile, job.res) {
  reg <- batchtools::makeRegistry(file.dir=regdir, work.dir=wkdir,
                                  conf.file=findConfFile(conffile))
  args <- list(fargs=fargs, data=data, fun=fun)
  id   <- batchtools::batchMap(estFun, ind.sample, more.args=args, reg=reg)
  doneSub <- batchtools::submitJobs(reg=reg, resources=job.res)
  return(list(reg=reg, id=id))
}

#' @keywords internal
.adj2elist <- function(G) {
    if (inherits(G, "sparseMatrix")) {
        G <- Matrix::triu(G, k=1)
        index_i_j <- Matrix::mat2triplet(G)[1:2]
        return(as.data.frame(index_i_j))
    } else {
        p <- ncol(G)
        return(arrayInd(which(as.logical(triu(G))), c(p,p)))
    }
}


#############################################

#' @export
plot.pulsar <- function(x, scale=TRUE, invlam=FALSE, loglam=FALSE, legends=TRUE, show = NULL, ...) {
    .plot.pulsar(x, scale, invlam, loglam, legends, show)
    return(invisible())
}


#' @keywords internal
.plot.pulsar <- function(x, scale=TRUE, invlam=FALSE, loglam=FALSE, legends=TRUE, show = NULL) {
    fin  <- getArgs(getCall(x), getEnvir(x))
    lams <- fin$fargs$lambda
    xlab <- "lambda"
    if (invlam) {lams <- 1/lams ; xlab <- paste("1/", xlab, sep="")}
    if (loglam) {lams <- log(lams) ; xlab <- paste("log[ ", xlab, " ]", sep="")}

    nlam  <- length(lams)
    fin$criterion <- setdiff(out.p$criterion, c("oracle_f1", "oracle_hamming"))
    crits <- fin$criterion
    
    # Filter criteria based on 'show' parameter
    if (!is.null(show) && length(show) > 0) {
      # Directly filter criteria based on 'show' array
      crits <- crits[crits %in% show]
    }
    
    n <- length(crits)
    if (scale) {
        ylab <- "summary (scaled)"
        if ("stars" %in% crits)
            ymax <- max(x$stars$summary)
        else ymax <- 1
    } else {
        ylab <- "summary"
        ymax <- max(unlist(lapply(crits, function(c) x[[ c ]]$summary)))
    }

    yrange <- c(0, ymax)
    plot(lams, seq(yrange[1], yrange[2], length.out=nlam),
         xlab=xlab, ylab=ylab, type='n')
    if (!is.null(x$stars$lb.index)) {
        ilams <- 1:length(lams)
        range1 <- ilams < x$stars$ub.index
        range2 <- ilams > x$stars$lb.index
        range  <- !(range1 | range2)
        ccol   <- vector('numeric', n+1)
        ltys   <- vector('numeric', n+1)
        legs   <- vector('numeric', n+1)
    } else {
        range1 <- rep(FALSE, nlam) ; range2 <- range1
        range  <- !range1
        ccol   <- vector('numeric', n)
        ltys   <- vector('numeric', n)
        legs   <- vector('numeric', n)
    }

    i <- 1 ; lcol <- 1
    optcrits <- c() ; optcols <- c()
    for (cr in crits) {
        summs <- x[[ cr ]]$summary
        optind <- opt.index(x, cr)
        if (scale && cr != "stars") summs <- ymax*summs/max(summs)
        if (length(summs) == nlam) {
            points(lams[range],  summs[range],  type='b', col=lcol)
            points(lams[range1], summs[range1], type='b', col=lcol, lty=2)
            points(lams[range2], summs[range2], type='b', col=lcol, lty=2)
            optind2 <- optind

            if (any(range1 | range2)) {
                ccol[i:(i+1)] <- c(lcol,lcol)
                ltys[i:(i+1)] <- c(2,1)
                legs[i:(i+1)] <- c(paste("b-", cr, sep=""), cr)
                i <- i+1
            } else {
                ccol[i] <- lcol
                ltys[i] <- 1
                legs[i] <- cr
            }
        } else {
            points(lams[range], summs, type='b', col=lcol)
            optind2 <- optind-which(range)[1]+1
            ccol[i] <- lcol
            ltys[i] <- 1
            legs[i] <- cr
        }

        if (!is.null(optind)) {
            points(lams[optind], summs[optind2], type='p', cex=1.5, pch=16, col=lcol)
            optcrits <- c(optcrits, cr)
            optcols  <- c(optcols , lcol)
        }
        lcol <- lcol + 1 ; i <- i + 1
    }

    if (legends) {
      legend('bottomleft', legs, col=ccol, pch=1, lty=ltys, cex=0.7)
      if (length(optcrits) > 0) {
        #legend('left', optcrits, pch=16, col=optcols, cex=0.5, title="opt lambda")
      }
    }
}

```













