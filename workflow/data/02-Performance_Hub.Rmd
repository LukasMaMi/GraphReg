---
title: "02-Performance_Hub"
output: github_document
---

## Step 3: Performance
```{r}

# Load session settings
#Hub_setting_path <- "C:/R Projekte/StARS_Simulations/workflow/Storage_Settings/"
Hub_setting_path <- "/Users/bropc/Documents/LMU/Master Statistics and Data Science/Masterarbeit/R Master/StARS_Simulations/workflow/Storage_Settings/"
hub_settings_file <- file.path(Hub_setting_path, "Hub_settings.RData")
load(hub_settings_file)

#dir_path3 <- "C:/R Projekte/StARS_Simulations/workflow/Storage_Performance_Hub"
dir_path3 <- "/Users/bropc/Documents/LMU/Master Statistics and Data Science/Masterarbeit/R Master/StARS_Simulations/workflow/Storage_Performance_Hub"

# Function to generate file names
get_filename <- function(config, rep, prefix = "Hub") {
  sprintf("%s_rep_%d_n_%d_p_%d.RData", prefix, rep, config$n, config$p)
}


# Function to calculate F1-score and Hamming distance
compute_metrics <- function(estimated, actual) {

  TP <- sum(estimated & actual)
  FP <- sum(estimated & !actual)
  FN <- sum(!estimated & actual)
  Precision <- ifelse(TP + FP > 0, TP / (TP + FP), 0)
  Recall <- ifelse(TP + FN > 0, TP / (TP + FN), 0)
  F1 <- ifelse(Precision + Recall > 0, 2 * (Precision * Recall) / (Precision + Recall), 0)
  # Calculate Hamming distance for the lower triangle only
  hamming_distance <- sum(tril(estimated) != tril(actual))

  
  list(F1 = F1, Hamming = hamming_distance)
}

# Initialize list to store results for each configuration
config_results <- list()

# Loop over configurations and repetitions
for(cfg in configs) {
  cfg_key <- paste("n", cfg$n, "p", cfg$p, sep="_")
  individual_results <- list()
  aggregated_metrics <- list(stars = NULL, gstars = NULL, oracle_f1 = NULL, oracle_hamming = NULL, null = NULL)
  
  lambda_values <- list(stars = numeric(), gstars = numeric(), oracle_f1 = numeric(), oracle_hamming = numeric())
  sparsity_values <- list(stars = numeric(), gstars = numeric(), oracle_f1 = numeric(), oracle_hamming = numeric())
  gap_values <- list(gap_b = numeric(), gap_beta = numeric())

  # Loop over repetitions for the current configuration
  for(rep in 1:num_repetitions) {
    load(paste0(dir_path2, "/", get_filename(cfg, rep, "estimation")))

    # Compute metrics
    stars_metrics <- compute_metrics(stars_graph, true_graph)
    gstars_metrics <- compute_metrics(gstars_graph, true_graph)
    oracle_metrics_f1 <- compute_metrics(oracle_graph_f1, true_graph)
    oracle_metrics_hamming <- compute_metrics(oracle_graph_hamming, true_graph)
    null_metrics <- compute_metrics(null_graph, true_graph)
    
    # Gap values
    gap_values$gap_b <- c(gap_values$gap_b, gap_b)
    gap_values$gap_beta <- c(gap_values$gap_beta, gap_beta)

    # Additional metrics: lambda values and sparsity
    additional_metrics <- list(
      stars_lambda = best_lambda_stars,
      gstars_lambda = best_lambda_gstars,
      oracle_lambda_f1 = best_lambda_oracle_f1,
      oracle_lambda_hamming = best_lambda_oracle_hamming,
      true_sparsity = act_sparsity,
      stars_sparsity = act_sparsity_stars,
      gstars_sparsity = act_sparsity_gstars,
      oracle_sparsity_f1 = act_sparsity_oracle_f1,
      oracle_sparsity_hamming = act_sparsity_oracle_hamming,
      stars_index = stars_index,
      stars_lb = stars_lb,
      stars_ub = stars_ub,
      gstars_index = gstars_index,
      oracle_index_f1 = oracle_index_f1,
      oracle_index_hamming = oracle_index_hamming
    )

    # Store individual results
    individual_results[[paste("Rep", rep)]] <- list(
      Stars = stars_metrics,
      GStars = gstars_metrics,
      Oracle_f1 = oracle_metrics_f1,
      Oracle_hamming = oracle_metrics_hamming,
      Additional = additional_metrics
    )

    # Accumulate metrics for aggregation
    # Convert to numeric and convert to a matrix format
    aggregated_metrics$stars <- rbind(aggregated_metrics$stars, as.numeric(unlist(stars_metrics)))
    aggregated_metrics$gstars <- rbind(aggregated_metrics$gstars, as.numeric(unlist(gstars_metrics)))
    aggregated_metrics$oracle_f1 <- rbind(aggregated_metrics$oracle_f1, as.numeric(unlist(oracle_metrics_f1)))
    aggregated_metrics$oracle_hamming <- rbind(aggregated_metrics$oracle_hamming, as.numeric(unlist(oracle_metrics_hamming)))
    aggregated_metrics$null <- rbind(aggregated_metrics$null, as.numeric(unlist(null_metrics)))
    
    # Accumulate lambda and sparsity values
    lambda_values$stars <- c(lambda_values$stars, additional_metrics$stars_lambda)
    sparsity_values$stars <- c(sparsity_values$stars, additional_metrics$stars_sparsity)
    lambda_values$gstars <- c(lambda_values$gstars, additional_metrics$gstars_lambda)
    sparsity_values$gstars <- c(sparsity_values$gstars, additional_metrics$gstars_sparsity)
    lambda_values$oracle_f1 <- c(lambda_values$oracle_f1, additional_metrics$oracle_lambda_f1)
    sparsity_values$oracle_f1 <- c(sparsity_values$oracle_f1, additional_metrics$oracle_sparsity_f1)
    lambda_values$oracle_hamming <- c(lambda_values$oracle_hamming, additional_metrics$oracle_lambda_hamming)
    sparsity_values$oracle_hamming <- c(sparsity_values$oracle_hamming, additional_metrics$oracle_sparsity_hamming)
    sparsity_values$null <- c(sparsity_values$null, additional_metrics$null)
  }
    
  calc_mean_ci <- function(data, lambda = NULL, sparsity = NULL) {
    
    mean_data <- colMeans(data, na.rm = TRUE)
    ci_data <- apply(data, 2, function(x) quantile(x, probs = c(0.025, 0.975), na.rm = TRUE))
    
    mean_lambda <- if (!is.null(lambda)) mean(lambda, na.rm = TRUE) else NA
    ci_lambda <- if (!is.null(lambda)) {
              if (length(lambda) > 1) {
                  apply(matrix(lambda, ncol = 1), 2, function(x) quantile(x, probs = c(0.025, 0.975), na.rm = TRUE))
              } else {
                  c(mean_lambda, mean_lambda) # Lower and upper bounds are both the mean
              }
           } else NA
    
    mean_sparsity <- if (!is.null(sparsity)) mean(sparsity, na.rm = TRUE) else NA
    
    list(Mean = mean_data, CI = ci_data, Lambda = mean_lambda, Lambda_CI = ci_lambda, Sparsity = mean_sparsity)
  }
  
  # Function to calculate mean gaps
  calc_mean_gaps <- function(gap_values) {
    mean(gap_values, na.rm = TRUE)
  }
  
  # Function to aggregate metrics
  aggregate_metrics <- function(metrics_list) {
  metrics_mat <- do.call(rbind, lapply(metrics_list, as.numeric))
  list(Mean = colMeans(metrics_mat, na.rm = TRUE),
       CI = apply(metrics_mat, 2, function(x) quantile(x, probs = c(0.025, 0.975), na.rm = TRUE)))
  }
  
  aggregated_gap_values <- list(
  gap_b_mean = calc_mean_gaps(gap_values$gap_b),
  gap_beta_mean = calc_mean_gaps(gap_values$gap_beta)
  )

  # Include mean lambda and sparsity in aggregated metrics
  aggregated_metrics$stars <- calc_mean_ci(aggregated_metrics$stars, lambda_values$stars, sparsity_values$stars)
  aggregated_metrics$gstars <- calc_mean_ci(aggregated_metrics$gstars, lambda_values$gstars, sparsity_values$gstars)
  aggregated_metrics$oracle_f1 <- calc_mean_ci(aggregated_metrics$oracle_f1, 
                                               lambda_values$oracle_f1, sparsity_values$oracle_f1)
  aggregated_metrics$oracle_hamming <- calc_mean_ci(aggregated_metrics$oracle_hamming, 
                                               lambda_values$oracle_hamming, sparsity_values$oracle_hamming)
  aggregated_metrics$null <- calc_mean_ci(aggregated_metrics$null, NULL, sparsity_values$null)
  
  
  # Store results for the current configuration
  config_results[[cfg_key]] <- list(
    Individual = individual_results,
    Aggregated = aggregated_metrics,
    Gap_Values = aggregated_gap_values
  )
}

# Save the results to a file
performance_filename <- "all_performance_results.RData"
save(config_results, file = file.path(dir_path3, performance_filename))

cat("Performance metrics for each configuration and repetition calculated and saved!\n")

```

