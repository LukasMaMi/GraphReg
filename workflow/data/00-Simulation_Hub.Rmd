---
title: "00-Simulation_Hub"
date: "Compiled at `r format(Sys.time(), '%Y-%m-%d %H:%M:%S', tz = 'UTC')` UTC"
output: github_document
params:
  name: "00-Simulation_Hub" # change if you rename file
---

# Simulations for Hub Graphs

## StARS Simulation (Liu et al. 2010)
* **Graph Structure:** The matrix rows/columns are partitioned into J equally-sized disjoint groups.
* **Groups:** Groups are denoted as V_1, V_2, ..., V_J such that their union forms the
set of all indices: V_1 U V_2 U ... U V_J = {1, ..., p}.
* **Pivotal Row:** Each of these groups V_k has an associated "pivotal" row denoted by k.
* **Size of Group:** The size of group V_1 is represented as s.
* **Omega (Precision Matrix) Structure:** For any index i in group V_k, the precision matrix elements Ω_ik and Ω_ki are set to value ρ. For any i not in V_k, the corresponding matrix elements are zero.
* **Experimental Details:** In Liu et al. (2010) the number of groups J is determined as J = floorfunct(p/s). The pivotal rows k are given by the sequence 1, s+1, 2s+1, ...
* **Rho value:** The value of ρ is given as ρ = (1/(s+1)) and in this context, s = 20, thus ρ = 1/21.
* **Number of Hubs g:** We have groups of size s = 20 for p = 40, therefore g = J = floor(p/s) .
* **Hub size:** According to Liu et al. (2010) s = 20.
* **Off-Diagonal Elements of Precision Matrix v:** Represent the strength of the connections in the graph. v =  ρ = (1/(s+1)) = 1/21.
* **Size of Subsampled Data Set:** According to Liu et al. (2010) b(n) = floor(10*sqrt(n))
* **Diagonal Elements of Precision Matrix Ω i.e. u:** According to Liu et al. (2010), the values of the diagonal elements of Ω are set to be one. This means that the variances of each individual variable are set to one. Therefore u = 1.
* **Number of Edges E:** E_l = p - g 
* **Sparsity Level:** Refers to the proportion of non-zero entries in the underlying true graphical model (i.e., the adjacency matrix or precision matrix). This gives an idea of how many edges (connections) are in the true graph compared to the total possible number of edges for a graph of that dimension.
* **Optimal Lambda:**  Determines the amount of penalty applied during the graphical model estimation process. A higher lambda will result in a sparser estimated graph (with fewer edges), while a lower lambda will allow for more edges. The optimal lambda is determined based on the stability of the graph structure across multiple subsamples.
* **Threshold beta:** The beta threshold is a user-defined value that decides the minimum proportion necessary for an edge to be considered "stable" and thus be included in the final graph. For instance, if the threshold is set to 0.1, it means an edge should be present in at least 10% of the subsamples to be considered stable.
* **Adjacency Matrix:** An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. For a simple graph (no self-loops or multiple edges) with vertex set V, the adjacency matrix A is a set of |V| x |V| where its element A_ij is 1 or non-negative, if there is an edge between vertix i and vertex j, and 0 otherwise.


## Simulate Synthetic Data
### 1) Hub1: for n = 800 and p = 40
```{r}
library(huge)
library(pulsar)

#Set Parameters
n <- 800 
p <- 40 
#Size of each hub group
s <- 20
#Number of hub groups
J <- floor(p/s) 
#Off-diagonal elements
rho <- (1/(s+1))
#Diagonal elements
u <- 0.001
#Subsampled dataset size 
b = (floor(10*sqrt(n)))/n
#Number of Subsamples N
N = 20


set.seed(123)
hub1 <- huge.generator(n = n, d = p, graph = "hub", v = rho, u = u, g = J, vis = TRUE)
hub1_data <- hub1$data

#Lambda path
lams_gs1  <- getLamPath(max = getMaxCov(hub1_data), min = 0.01, len = 40)
lambda <- list(lambda=lams_gs1)

true_graph <- hub1$theta
true_cov <- hub1$sigma

#Plot Adjacency Matrix
huge.plot(hub1$theta)
```


```{r}

#Define QUIC as method of choice
library(QUIC)
quicr <- function(hub1_data, lambda, ...) {
S <- cov(hub1_data)
est <- QUIC(S, rho = 1, path = lambda, msg = 0, tol = 1e-2, ...)
est$path <- lapply(seq(length(lambda)), function(i) {
## convert precision array to adj list
tmp <- est$X[,,i]; diag(tmp) <- 0
as(tmp!=0, "lMatrix") #Here change format into "lsCMatrix"!!!!
})
est
}

#Run pulsar package
library(orca)
set.seed(123)
out.p_gs1 <- pulsar(
      hub1_data,
      fun = quicr,
      fargs = lambda,
      criterion = c('stars', 'gcd'),
      thresh = 0.1,
      subsample.ratio = b,
      rep.num = N,
      seed = NULL,
      lb.stars = TRUE,
      ub.stars = TRUE,
      ncores = 1,
      refit = FALSE
)
#Get optimal index for gcd
lam_gam <- get.opt.index(out.p_gs1, criterion = "gcd")
#Set optimal index for gcd
opt.index(out.p_gs1, criterion = "gcd") <- lam_gam


out.p_gs1
plot(out.p_gs1, scale = T, invlam = FALSE, loglam = FALSE, legends = FALSE)

fit  <- refit(out.p_gs1, criterion = c("stars", "gcd"))
print(fit)

stars_graph <- fit[["refit"]][["stars"]]
gstars_graph <- fit[["refit"]][["gcd"]]

```


### Oracle
```{r}

# Oracle with QUIC
oracle_quic <- function(true_cov, lambda, ...) {
    est <- QUIC(true_cov, rho = 1, path = lambda, msg = 0, tol = 1e-2, ...)
    est$path <- lapply(seq(length(lambda)), function(i) {
        tmp <- est$X[,,i]
        diag(tmp) <- 0
        as(tmp != 0, "lMatrix")
    })
    est
}

oracle_results <- oracle_quic(true_cov, lams_gs1) #Bis hier OK!

oracle_results$X
oracle_results$X
oracle_results$opt

# Minimize total number of different edges between the estimated and true graph
best_lambda_index <- which.min(sapply(1:length(lams_gs1), function(i) {
    estimated_graph <- oracle_results$path[[i]]
    sum(estimated_graph != true_graph)
}))

best_lambda <- lams_gs1[best_lambda_index]

#Extract the oracle precision matrix for the best lambda:
oracle_best_precision_matrix <- oracle_results$X[,,best_lambda_index]

#Plot the oracle graph:
oracle_graph <- oracle_best_precision_matrix !=0

huge.plot(oracle_graph)

```

### 1.4) G-Stars: F1-Scores and Jaccard-Index for Hub1
```{r}

true_graph 
oracle_graph
true_cov

stars_graph
gstars_graph

oracle_graph[oracle_graph == TRUE] <- 1
oracle_graph[oracle_graph == FALSE] <- 0

library(Matrix)
dense_to_sparse <- function(mat) {
  s_mat <- as(mat, "CsparseMatrix")
  as(s_mat, "lMatrix")
}

oracle_graph <- dense_to_sparse(oracle_graph)
true_graph  <- dense_to_sparse(true_graph) 
true_cov  <- dense_to_sparse(true_cov) 

# 1. Extract the estimated graph structure (estimated adjacency matrix)

fit_gs1  <- refit(out.p_gs1, criterion = c("stars", "gcd"))
print(fit_gs1)

est_graph_stars <- fit_gs1[["refit"]][["stars"]]
est_graph_gstars <- fit_gs1[["refit"]][["gcd"]]

# 3. Compute the metrics
# Convert the matrices to binary (1 for edge, 0 for no edge)
est_bin_gs1 <- as.numeric(oracle_graph != 0)
true_bin_gs1 <- as.numeric(true_graph != 0)

# Compute true positives, false positives, true negatives, and false negatives
TP_gs1 <- sum(est_bin_gs1 == 1 & true_bin_gs1 == 1)
FP_gs1 <- sum(est_bin_gs1 == 1 & true_bin_gs1 == 0)
TN_gs1 <- sum(est_bin_gs1 == 0 & true_bin_gs1 == 0)
FN_gs1 <- sum(est_bin_gs1 == 0 & true_bin_gs1 == 1)

# Calculate precision, recall, F1-score (Sl. 8), and Jaccard index
precision_gs1 <- TP_gs1 / (TP_gs1 + FP_gs1)
recall_gs1 <- TP_gs1 / (TP_gs1 + FN_gs1)
F1_gs1 <- 2 * (precision_gs1 * recall_gs1 / (precision_gs1 + recall_gs1))
jaccard_index_gs1 <- TP_gs1 / (TP_gs1 + FP_gs1 + FN_gs1)

cat("F1-score:", F1_gs1, "\n")
cat("Jaccard Index:", jaccard_index_gs1, "\n")



```



```{r}
oracle_bin <- as.numeric(oracle_best_graph)

TP_oracle <- sum(oracle_bin == 1 & true_bin_gs1 == 1)
FP_oracle <- sum(oracle_bin == 1 & true_bin_gs1 == 0)
TN_oracle <- sum(oracle_bin == 0 & true_bin_gs1 == 0)
FN_oracle <- sum(oracle_bin == 0 & true_bin_gs1 == 1)

precision_oracle <- TP_oracle / (TP_oracle + FP_oracle)
recall_oracle <- TP_oracle / (TP_oracle + FN_oracle)
F1_oracle <- 2 * (precision_oracle * recall_oracle / (precision_oracle + recall_oracle))
jaccard_index_oracle <- TP_oracle / (TP_oracle + FP_oracle + FN_oracle)

cat("Oracle F1-score:", F1_oracle, "\n")
cat("Oracle Jaccard Index:", jaccard_index_oracle, "\n")

```



## Loop over all repetitions
```{r}

# Manually set the number of repetitions
num_repetitions <- 2 

# Specify configurations
configs <- list(
  list(n=800, p=40),
  list(n=400, p=100),
  list(n=200, p=200)
)

# Initialize matrices to store F1 scores
F1_stars_matrix <- matrix(0, nrow=num_repetitions, ncol=length(configs))
F1_gcd_matrix <- matrix(0, nrow=num_repetitions, ncol=length(configs))
F1_oracle_matrix <- matrix(0, nrow=num_repetitions, ncol=length(configs))

for(rep in 1:num_repetitions){
  
# Function to run experiment
run_hub <- function(n, p) {
  
  # 1. Set Parameters
  # Size of each hub group
  s <- 20
  # Number of hub groups
  J <- floor(p/s) 
  # Off-diagonal elements
  rho <- (1/(s+1))
  # Diagonal elements
  u <- 0.001
  # Subsampled dataset size 
  b = (floor(10*sqrt(n)))/n
  # Number of Subsamples N
  N = 20
  
  # 2. Data Generation
  hub <- huge.generator(n = n, d = p, graph = "hub", v = rho, u = u, g = J, vis = TRUE)
  hub_data <- hub$data
  
  true_graph <- hub$theta !=0
  true_cov <- hub$sigma
  
  #Define lambda path
  lambda_path  <- getLamPath(max = getMaxCov(hub_data), min = 0.01, len = 40)
  lambda <- list(lambda=lambda_path)
  
  # 3. Run QUIC method
  quicr <- function(hub_data, lambda, ...) {
  S <- cov(hub_data)
  est <- QUIC(S, rho = 1, path = lambda, msg = 0, tol = 1e-2, ...)
  est$path <- lapply(seq(length(lambda)), function(i) {
  ## convert precision array to adj list
  tmp <- est$X[,,i]; diag(tmp) <- 0
  as(tmp!=0, "lMatrix")
  })
  est
  }

  # Run pulsar package
  out.p <- pulsar(
      hub_data,
      fun = quicr,
      fargs = lambda,
      criterion = c('stars', 'gcd'),
      thresh = 0.1,
      subsample.ratio = b,
      rep.num = N,
      seed = NULL,
      lb.stars = TRUE,
      ub.stars = TRUE,
      ncores = 1,
      refit = FALSE
  )
  # Get optimal index for gcd
  lam_gam <- get.opt.index(out.p, criterion = "gcd")
  # Set optimal index for gcd
  opt.index(out.p, criterion = "gcd") <- lam_gam

  fit  <- refit(out.p, criterion = c("stars", "gcd"))
  stars_graph <- fit[["refit"]][["stars"]]
  gstars_graph <- fit[["refit"]][["gcd"]]

  # 4. Run Oracle QUIC
  oracle_quic <- function(true_cov, lambda, ...) {
  est <- QUIC(true_cov, rho = 1, path = lambda, msg = 0, tol = 1e-2, ...)
  est$path <- lapply(seq(length(lambda)), function(i) {
    tmp <- est$X[,,i]
    diag(tmp) <- 0
    as(tmp != 0, "lMatrix")
  })
  est
  }

  oracle_results <- oracle_quic(true_cov, lambda_path)

  # Minimize total number of different edges between the estimated and true graph
  best_lambda_index <- which.min(sapply(1:length(lambda_path), function(i) {
    estimated_graph <- oracle_results$path[[i]]
    sum(estimated_graph != true_graph)
  }))

  best_lambda <- lambda_path[best_lambda_index]

  # Extract the oracle precision matrix for the best lambda:
  oracle_graph <- oracle_results$X[,,best_lambda_index]
  oracle_graph[oracle_graph == TRUE] <- "1"
  oracle_graph[oracle_graph == FALSE] <- "0"

  
  # 5. Calculate metrics
 
  # List of estimated graphs
  estimated_graphs <- list(stars = stars_graph, gstars = gstars_graph, oracle = oracle_graph)

  # Create empty lists to store results
  F1_scores <- list()
  jaccard_indices <- list()

  # Loop through each estimated graph and calculate metrics
  for (name in names(estimated_graphs)) {
  
  # Convert the matrices to binary (1 for edge, 0 for no edge)
  est_bin <- as.numeric(estimated_graphs[[name]] != 0)
  true_bin <- as.numeric(true_graph != 0)

  # Compute true positives, false positives, true negatives, and false negatives
  TP <- sum(est_bin == 1 & true_bin == 1)
  FP <- sum(est_bin == 1 & true_bin == 0)
  TN <- sum(est_bin == 0 & true_bin == 0)
  FN <- sum(est_bin == 0 & true_bin == 1)

  # Calculate precision, recall, F1-score, and Jaccard index
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * (precision * recall) / (precision + recall)
  jaccard_index <- TP / (TP + FP + FN)

  # Save results to lists
  F1_scores[[name]] <- F1
  jaccard_indices[[name]] <- jaccard_index
  }
  
  return(list(F1_stars = F1_scores[["stars"]], F1_gcd = F1_scores[["gstars"]], F1_oracle = F1_scores[["oracle"]]))

  }

  results <- lapply(configs, function(cfg) run_hub(n = cfg$n, p = cfg$p))  

  # Update the matrices with the results of this repetition
  F1_stars_matrix[rep, ] <- sapply(results, function(x) x$F1_stars)
  F1_gcd_matrix[rep, ] <- sapply(results, function(x) x$F1_gcd)
  F1_oracle_matrix[rep, ] <- sapply(results, function(x) x$F1_oracle)
    
}

# Compute average scores
avg_F1_stars <- colMeans(F1_stars_matrix)
avg_F1_gcd <- colMeans(F1_gcd_matrix)
avg_F1_oracle <- colMeans(F1_oracle_matrix)

desired_order <- sapply(configs, function(x) paste0("n=", x$n, " p=", x$p))

# Update the df to contain the average scores
df <- data.frame(np_setting = desired_order, 
                 F1_stars = avg_F1_stars,
                 F1_gcd = avg_F1_gcd,
                 F1_oracle = avg_F1_oracle)

df$np_setting <- factor(df$np_setting, levels = desired_order, ordered = TRUE)


```



## Plotting F1-Scores over all repetitions for all configurations
```{r}
# Plotting the results
ggplot(df, aes(x=np_setting)) + 
  geom_line(aes(y=F1_stars, color="Stars", group="Stars"), linetype="dotted", color="lightblue", linewidth=1.5) + 
  geom_line(aes(y=F1_gcd, color="GCD", group="GCD"), linetype="dotted", color="darkorange", linewidth=1.5) + 
  geom_line(aes(y=F1_oracle, color="Oracle", group="Oracle"), linetype="solid", color="black", linewidth=1.5) + 
  geom_point(aes(y=F1_stars, color="Stars"), size=1.5) +
  geom_point(aes(y=F1_gcd, color="GCD"), size=1.5) +
  geom_point(aes(y=F1_oracle, color="Oracle"), size=1.5) +
  labs(title = "Hub", y = "F1-score") + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14)) + 
  scale_color_manual(values=c("Stars"="lightblue", "GCD"="darkorange", "Oracle"="black"), 
                     name="Method",
                     breaks=c("Stars", "GCD", "Oracle"))

```










### Session info
```{r}
sessionInfo()
```

